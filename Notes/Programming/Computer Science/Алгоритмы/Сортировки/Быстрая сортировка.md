Когда в 1960 году Тони Хоар придумывал этот алгоритм, ему нужно было отсортировать данные на магнитной ленте за один проход, чтобы не перематывать плёнку много раз. Для этого он взял за основу классическую пузырьковую сортировку и преобразовал её так:

1. На очередном шаге выбирается опорный элемент — им может быть любой элемент массива.
2. Все остальные элементы массива сравниваются с опорным и те, которые меньше него, ставятся слева от него, а которые больше или равны — справа.
3. Для двух получившихся блоков массива (меньше опорного, и больше либо равны опорному) производится точно такая же операция — выделяется опорный элемент и всё идёт точно так же, пока в блоке не останется один элемент.

![[Быстрая сортировка.gif]]
  
Синяя линия — это значение опорного элемента, а серый блок показывает, какую часть массива сортирует алгоритм

**Имплементация:**
``
```
int Partition(vector<int>& values, int l, int r) { 
	int x = values[r]; 
	int less = l; 
	for (int i = l; i < r; ++i) { 
		if (values[i] <= x) { 
			swap(values[i], values[less]); 
			++less; 
		} 
	} 
	swap(values[less], values[r]); 
	return less; 
} 

void QuickSortImpl(vector<int>& values, int l, int r) { 
	if (l < r) { 
		int q = Partition(values, l, r); 
		QuickSortImpl(values, l, q - 1); 
		QuickSortImpl(values, q + 1, r); 
	} 
}

void QuickSort(vector<int>& values) { 
	if (!values.empty()) { 
		QuickSortImpl(values, 0, values.size() - 1); 
	} 
}
```


**Сложность:**

**Временная сложность:**

1. **В худшем случае**: O(n²)
   Это происходит, если в качестве опорного элемента (**pivot**) выбирается наихудший элемент, например:
   - Минимальный или максимальный элемент массива
   - Массив уже отсортирован (или почти отсортирован).
   В этом случае деление массива происходит крайне неравномерно: один подмассив содержит n-1 элемент, а второй — пуст.

2. **В среднем случае**: O($n \log n$)
   При случайном выборе опорного элемента деление массива, как правило, происходит равномерно. Таким образом, каждый уровень рекурсии требует O(n) операций для деления массива, а глубина рекурсии составляет O(\log n).

3. **В лучшем случае**: $O(n \log n)$
   Это достигается, когда деление массива всегда идеально сбалансировано (размер подмассивов примерно одинаков).

**Пространственная сложность:**

1. **Средний случай**: O(\log n)
   Пространственная сложность связана с глубиной рекурсии. При сбалансированном делении массива глубина рекурсии пропорциональна O(\log n).

2. **Худший случай**: O(n)
   Если деление крайне неравномерное (например, n-1 элементов в одном подмассиве), глубина рекурсии достигает n.

3. **Дополнительная память**:
   QuickSort — это алгоритм **in-place** (встроенный), если использовать левойчастичное копирование данных. В этом случае дополнительные массивы для хранения подмассивов не требуются, кроме стека вызовов.