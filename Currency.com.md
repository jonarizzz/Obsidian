## Data structures

##### Легко

1. В чём разница между [[Стек (Stack)||Стеком]] и [[Очередь (Queue)||Очередью]]?
	1. Стек = первым пришёл — последним ушёл
	2. Очередь = первым пришёл — первым ушёл
2. В чём разница между [[Односвязный список (Singly Linked List)||Однонаправленным]] и [[Двусвязный список (Doubly Linked List)||Двунаправленым списком]]?
	1. [[Односвязный список (Singly Linked List)||Однонаправленный]] = ссылка только на следующий элемент
	2. [[Двусвязный список (Doubly Linked List)||Двунаправленный]] = ссылка на предыдущий и на следующий элементы
3. В чём разница между [[Куча (Heap)||Кучей]] и [[Стек (Stack)||Стеком]]?
	1. [[Стек (Stack)||Стек]] = это структура данных типа LIFO, где элементы добавляются и удаляются только с вершины; используется для временного хранения, например, в стеке вызовов
	2. [[Куча (Heap)||Куча]] = это дерево, где элементы упорядочены по приоритету (минимум или максимум), и применяется для задач с очередями приоритетов и алгоритмов графов
	3. Главная разница: стек ориентирован на последовательный доступ, а куча — на управление приоритетами

##### Средне

1. Сравните алгоритмы сортировки [[Сортировка слиянием (Merge Sort)||Слиянием]] и [[Быстрая сортировка (Quick Sort)||Быструю Сортировку]]. Какая лучше?
	1. [[Сортировка слиянием (Merge Sort)||Сортировка Cлиянием]] = гарантированное $O(n \log n)$ для всех случаев + $O(n)$ для хранения отсортированного подмассива.
	2. [[Быстрая сортировка (Quick Sort)||Быстрая Сортировка]] = $O(n \log n)$ – в лучшем и $O(n²)$ – в худшем + $O(\log n)$ на хранение рекурсии. 
	3. Ответ: для гарантированной производительности без худших случаев – Слиянием, для ограниченной памяти – Быстрая. 
2. В чём разница между [[HashMap]] и [[TreeMap]]?
	1. [[HashMap]] = основан на хэш-таблице, обеспечивает быстрый доступ к элементам ($O(1)$ в среднем случае), но не сохраняет порядок ключей. Подходит для задач, где важна производительность, а порядок не имеет значения.
	2. [[TreeMap]] = использует красно-чёрное дерево, хранит ключи в отсортированном порядке (по возрастанию или с использованием [[{TODO} Comparable (интерфейс)||Comparator]]) и имеет сложность операций $O(\log n)$. Его выбирают, когда требуется упорядоченность элементов.
3. Какая сложность у [[TreeMap]]?
	1. Операции с [[TreeMap||TreeMap]], такие как вставка, удаление и поиск элементов, имеют сложность $O(\log n)$
4. В чём разница между HashMap и ConcurrentHashMap? 
	1. [[HashMap||HashMap]] = Не потокобезопасен. Подходит для использования в одном потоке. При доступе из нескольких потоков требуется внешняя синхронизация.
	2. [[ConcurrentHashMap]] = Потокобезопасен. Подходит для использования в многопоточной среде. Использует механизм сегментации (или шардирования) для уменьшения блокировок, что позволяет нескольким потокам работать с картой одновременно.
5. В чём разница между [[Двоичное Дерево (Binary Tree)||Двоичным деревом]] и [[Двоичное Дерево Поиска (Binary Search Tree)||Двоичным Деревом Поиска]]?
	1. [[Двоичное Дерево (Binary Tree)||Двоичное Дерево]] = два потомка у каждого узла
	2. [[Двоичное Дерево Поиска (Binary Search Tree)||Двоичное Дерево Поиска]] = значение левого потомка < значение родителя < значение правого потомка
6. В каких случаях использовать [[Двоичное Дерево (Binary Tree)||Двоичное Дерево]] вместо [[Двусвязный список (Doubly Linked List)||Двусвязного Списка]]?
	1. [[Двоичное Дерево (Binary Tree)||Двоичное Дерево]] = когда нужно хранить данные в структурированном и иерархическом виде с быстрым доступом и поиском (например, для поиска по ключу). Оно эффективно для операций вставки, удаления и поиска в среднем за $O(\log n)$ времени.
	2. [[Двусвязный список (Doubly Linked List)||Двусвязный Список]] =  полезен, когда важна простота добавления и удаления элементов в любом месте списка, без необходимости в быстрых поисках по ключу. Он идеально подходит для сценариев, где порядок элементов меняется динамически, а доступ по индексу не требуется.

##### Сложно

1. Знаете ли вы какие-либо структуры данных, которые работают лучше, чем [[HashMap||HashMap]], в тех случаях, когда контроль использования памяти очень важен?
	1. [[TreeMap]] — если нужен порядок, без авторасширения.
	2. [[{TODO} LinkedHashMap||LinkedHashMap]] с ограничением — контролируйте размер вручную.
	3. [[Префиксное дерево (Trie)||Trie]] — для эффективного хранения строк.
	4. [[{TODO} Bloom Filter]] — для проверки существования без хранения данных.
2. Какие есть методы разрешения [[Коллизии при хэшировании (Hash Collision)||коллизий]]?
	1. **Открытая адресация** – хороша для компактности:
		1. **Линейное пробирование**: поиск следующей свободной ячейки.
		2. **Квадратичное пробирование**: поиск с квадратичным шагом.
		3. **Двойное хэширование**: использование второй хэш-функции для шага.
	2. **Цепочки (Chaining)** – в каждой ячейке хранится список элементов с одинаковым хэшом. Хороши для гибкости.
	3. **Ре-хэширование** – увеличение размера таблицы и перерасчет хэшей.
	4. **Куки-хэширование** – элемент может храниться в нескольких ячейках, при коллизии происходит вытеснение.
	5. **Перфектное хэширование** – создается идеальная хэш-функция, исключающая коллизии.
3. В каких случаях имеет смысл использовать самобалансирующиеся двоичные деревья поиска ([[AVL-дерево||AVL-дерево]] и [[Красно-чёрное дерево (Red-Black Tree)||Красно-Чёрное Дерево]])?
	1. **Общая выгода:**
		1. **Детерминированная сложность:** Всегда $O(\log n)$, независимо от порядка данных.
		2. **Упорядоченность:** Подходит для работы с диапазонами и сортировкой.
		3. **Гибкость:** Лучше [[Хэш-таблица (Hash Table)||хэш-таблиц]], если требуется сохранение порядка.
	2. **Индексация в базах данных**
		1. Свойство: Быстрый поиск, вставка, удаление ($O(\log n)$).
		2. Почему: Данные всегда отсортированы, подходят для диапазонных запросов.
	3. **Множества и словари**
		1. **Свойство:** Упорядоченные ключи, уникальность.
		2. **Почему:** Подходят для структур [[{TODO} TreeSet||TreeSet]] и [[TreeMap||TreeMap]], обеспечивая сортировку и быструю навигацию.
	4. **Логи и временные метки**
		1. **Свойство:** Упорядоченность для временных данных.
		2. **Почему:** Быстро находят записи по диапазону (например, за конкретный день).
	5. **Компиляторы**
		1. **Свойство:** Быстрый доступ к идентификаторам.
		2. **Почему:** Используются для таблиц символов с частым добавлением/поиском.
	6. **Очереди с приоритетом**
		1. **Свойство:** Хранение в порядке приоритетов.
		2. **Почему:** Легче поддерживать упорядоченность, чем в [[Куча (Heap)||кучах]], для частых изменений.
4. Знаете ли вы какие-нибудь готовые к использованию неблокирующие коллекции в Java? Какую базовую и внутреннюю стратегию они используют?
	1. [[ConcurrentHashMap||ConcurrentHashMap]] – Неблокирующий потокобезопасный вариант [[Хэш-таблица (Hash Table)||хэш-таблицы]].
	2. [[ConcurrentLinkedQueue]] – Неблокирующая очередь, основанная на связном списке.
	3. [[ConcurrentLinkedDeque]] – Неблокирующая двунаправленная очередь.
	4. [[CopyOnWriteArrayList]] – Потокобезопасный список, который копирует массив при каждой операции записи.
	5. [[ConcurrentSkipListMap]] – потокобезопасная сортированная мапа, основанная на SkipList.
	6. [[ConcurrentSkipListSet]] – потокобезопасное множество, основанное на [[ConcurrentSkipListMap]].
	7. Atomic структуры – структуры данных, хранящие [[Атомики (Atomics)||атомики]] (например, [[AtomicIntegerArray]], [[AtomicReferenceArray]])

##### Очень сложно

- Какую структуру данных нужно использовать для создания [[{TODO} LRU (Least Recently Used)]] кэша?
	- Стандартное решение = [[Хэш-таблица (Hash Table)||Хэш-таблица]] + [[Двусвязный список (Doubly Linked List)||Двусвязный список]]
	- [[Хэш-таблица (Hash Table)||Хэш-таблица]] = для хранения данных и для быстрого поиска по ключу ($O(1)$). 
	- [[Двусвязный список (Doubly Linked List)||Двусвязный список]] = для хранения порядка использования элементов. 
- Какова временная сложность добавления нового узла в [[Двоичное Дерево (Binary Tree)||двоичное дерево]]?
	- Для [[Сбалансированное Дерево (Balanced Tree)||сбалансированных]] [[Двоичное Дерево (Binary Tree)||двоичных деревьев]] – высота сбалансированного дерева пропорциональна [[Логарифм||логарифму]] от числа узлов, и поиск места для вставки происходит за время $O(\log n)$, где $n$ — количество узлов в дереве.
	- Для несбалансированных двоичных деревьев (например, если дерево превращается в список при добавлении элементов) – $O(n)$ времени, где $n$ — количество узлов в дереве.


---
## Databases

##### Легко

- В чём разница между [[Первичный Ключ (Primary Key)||Primary Keys]], [[Уникальный Ключ (Unique Key)||Unique Keys]] и [[Внешний Ключ (Foreign Key)||Foreign Keys]]
	- [[Первичный Ключ (Primary Key)||Primary Key]] = Уникально идентифицирует запись, не допускает `NULL`, только один на таблицу.
	- [[Уникальный Ключ (Unique Key)||Unique Key]] = Обеспечивает уникальность значений, допускает `NULL`, можно иметь несколько.
	- [[Внешний Ключ (Foreign Key)||Foreign Key]] = Связывает таблицы, ссылается на первичный ключ другой таблицы.
- Напишите SQL-запрос для расчета количества активных сотрудников по отделам, если количество сотрудников в отделе >= 1. [[Синтаксис SELECT (FROM, WHERE, GROUP BY, HAVING, ORDER BY)||Синтаксис SELECT]] , [[Синтаксис COUNT]]
```sql
SELECT 
    department_id,
    COUN. (*) AS active_employee_count 
FROM 
    employees
WHERE 
    status = 'active'
GROUP BY 
    department_id
HAVING 
    COUNT(*) >= 1;
```

- Что такое [[Схема (Schema)||схемы (schemas)]] в СУБД и как они могут помочь организовать данные в многопользовательском приложении Java (multi-tenant Java application)?
	- [[Схема (Schema)||Схема]] = логическое пространство имен, которое группирует таблицы, индексы, представления и другие объекты.
	- Применение:
		- Изоляция данных – каждому клиенту выделяется отдельная схема (например, tenant1, tenant2).
		- Управление доступом – установление прав на уровне схем.
		- Масштабируемость – легкое добавление новых клиентов без влияния на существующих.
		- Удобство обслуживания – обновления и резервные копии выполняются для конкретного клиента.
- В чем разница между [[Таблица БД (DB Table)||таблицей (table)]] и [[Представление (View)||представлением (view)]] в PostgreSQL? Как бы вы использовали каждый из них в приложении Java?
	- [[Таблица БД (DB Table)||Таблица]] = физическая структура базы данных, в которой хранятся данные. Используйте таблицы для хранения и управления данными.
	- [[Представление (View)||Представление]] = логическая структура, представляющая собой результат запроса SQL. Используйте для агрегирования данных, ограничения доступа (например, предоставления данных только определенным пользователям), упрощения запросов или реализации бизнес-логики.


##### Средне

- Как СУБД обеспечивает соответствие [[ACID||ACID]] и почему это важно для транзакционных приложений Java?
	- Атомарность = транзакция выполняется полностью или откатывается. Защищает от частичных изменений данных.
	- Консистентность = данные остаются целостными, соблюдаются все ограничения ([[Внешний Ключ (Foreign Key)||внешние ключи]], [[Уникальный Ключ (Unique Key)||уникальность]] и т.п.)
	- Изолированность = параллельные транзакции не влияют друг на друга, предотвращая ошибки, например, [[Грязное Чтение (Dirty Read)||грязные чтения]].
	- Надёжность = данные сохраняются даже при сбоях (отключение электричества)
	- Java-приложения используют [[ACID||ACID]] для работы с базами через [[{TODO} JPA||JPA]]/[[{TODO} Hibernate||Hibernate]] или [[{TODO} Spring||Spring]], чтобы гарантировать надежность, особенно в критичных системах (банки, магазины, бронирования).
- С какими наиболее распространенными проблемами производительности сталкиваются разработчики при работе с [[Реляционные Базы Данных (Relational Database)||реляционной базой данных]], которая является [[Высокая Согласованность (Strong Consistency)||высокосогласованной]]? Почему они происходят?
	- Медленные записи: синхронизация данных между [[Репликация (Replication)||репликами]] замедляет операции записи.
	- Высокие задержки: синхронизация данных между узлами увеличивает время отклика.
	- Перегрузка сети: необходимость постоянного обмена данными между узлами снижает производительность.
	- Конфликты данных: при одновременных изменениях возникают дополнительные накладные расходы на разрешение конфликтов.
	- Низкая доступность: в случае сбоя системы нужно ждать восстановления согласованности, что снижает доступность.
- Почему добавление слишком большого количества [[Индекс (Index)||индексов]] плохо? Каковы узкие места этого?
	- Много индексов ухудшают производительность при вставке, обновлении и удалении данных, требуют больше памяти и увеличивают нагрузку на систему. 
	- Они могут замедлить запросы, так как база данных тратит время на обновление индексов. 
	- Важно оптимизировать их количество и тип под реальные нужды.
- Какие есть варианты гарантировать согласованность в базе данных, если несколько процессов записывают/читают в одну и ту же таблицу (строку)? Имеет ли значение уровень изоляции базы данных?
	- Блокировки:
		- [[Пессимистичная Блокировка (Pessimistic Locking)]] = Процесс блокирует строку или таблицу для других, пока не завершит свою операцию.
		- [[Оптимистичная Блокировка (Optimistic Locking)]] = Процесс пытается выполнить операцию, и если кто-то изменил данные, то процесс проверяет и повторяет попытку.
	- [[Транзакция (Transaction)||Транзакции]] = Все изменения происходят в рамках транзакции, что гарантирует, что данные будут либо изменены полностью, либо не изменены вовсе.
	- [[Уровни Изоляции Транзакций (Transaction Isolation Levels)||Уровни изоляции транзакций]]:
		- [[Read Committed]] = Можно читать только подтвержденные данные, но возможны проблемы с параллельными изменениями.
		- [[Repeatable Read]] = Защищает от изменений, которые могут быть сделаны другими процессами.
		- [[Serializable]] = Гарантирует полную изоляцию между транзакциями, но снижает производительность.
- Какие уровни изоляции транзакций вы знаете? Как вы думаете, почему их так много?
	- [[Read Uncommitted||Read Uncommitted]]: позволяет читать неподтвержденные данные.
	- [[Read Committed||Read Committed]]: позволяет читать только зафиксированные данные.
	- [[Repeatable Read||Repeatable Read]]: предотвращает повторяющиеся чтения.
	- [[Serializable||Serializable]]: самый строгий уровень, транзакции выполняются последовательно, предотвращает все проблемы, но снижает производительность.
	- Причина = баланс между производительностью и консистентностью.
- Какой уровень изоляции по умолчанию для транзакций в Postgres?
	- [[Read Committed||Read Committed]]: позволяет читать только зафиксированные данные.
- Объясните разницу между [[Пессимистичная Блокировка (Pessimistic Locking)||пессемистической]] и [[Оптимистичная Блокировка (Optimistic Locking)||оптимистической]] блокировкой в ​​Postgres.
	- [[Пессимистичная Блокировка (Pessimistic Locking)||Пессимистическая блокировка]] захватывает блокировки на данные сразу, чтобы предотвратить их изменение другими транзакциями, что может привести к задержкам.
	- [[Оптимистичная Блокировка (Optimistic Locking)||Оптимистическая блокировка]] не захватывает блокировки заранее, а проверяет изменения данных в конце [[Транзакция (Transaction)||транзакции]], и если данные изменены, [[Транзакция (Transaction)||транзакция]] [[Откат Транзакции (Rollback)||откатывается]], что более эффективно при низкой вероятности конфликтов.
- Какова цель [[Синтаксис EXPLAIN||EXPLAIN и EXPLAIN ANALYSE]] в Postgres? Как они помогают оптимизировать запросы?
	- EXPLAIN = показывает план выполнения запроса, включая оценку затрат на операции, что помогает выявить неэффективные участки.
	- EXPLAIN ANALYSE = выполняет запрос и отображает реальные данные о времени выполнения и количестве обработанных строк, позволяя точнее оценить производительность запроса.
- Что такое [[Пул Соединений (Connection Pool)||пул соединений]] и как бы вы реализовали его с помощью таких инструментов, как HikariCP с Postgres в приложении Java? 
	- [[Пул Соединений (Connection Pool)||Пул соединений (Connection Pool)]] = механизм для повторного использования заранее созданных соединений с базой данных, что снижает накладные расходы на установление новых соединений.
	- HikariCP = это быстрый и эффективный [[Пул Соединений (Connection Pool)||пул соединений]] для Java. Для его использования с PostgreSQL нужно настроить HikariDataSource с параметрами подключения (URL, имя пользователя, пароль) и задать параметры пула (например, максимальное количество соединений и тайм-ауты). HikariCP автоматически управляет соединениями, что повышает производительность и уменьшает нагрузку на систему.
- Что такое [[Материализированное Представление (Materialized View)||материализованные представления]] в Postgres и чем они отличаются от [[Представление (View)||обычных представлений]]?
	- [[Представление (View)||View]] = это виртуальная таблица, основанная на SQL-запросе, данные в которой обновляются при каждом запросе.
	- [[Материализированное Представление (Materialized View)||Materialized View]] = это физическая копия данных, созданная на основе SQL-запроса, которая хранится на диске.

##### Сложно

- Что такое [[Шардинг (Sharding)||шардинг]]? В каких случаях следует выбирать [[Шардинг (Sharding)||шардинг]] вместо [[Партиционирование (Секционирование, Partitioning)||партиционирования]]?
	- [[Шардинг (Sharding)||Шардинг]] = разделение данных между несколькими независимыми серверами для горизонтального масштабирования и распределения нагрузки. Если данные не помещаются на одном сервере, нужна масштабируемость.
	- [[Партиционирование (Секционирование, Partitioning)||Партиционирование]] = логическое разделение данных внутри одной базы для оптимизации запросов. Если данные можно хранить на одном сервере, нужна локальная оптимизация.
- В каких случаях база данных может выбрать [[Последовательное Сканирование (Sequential Scan)||sequential scan]], даже если для таких критериев есть соответствующий индекс? (устаревшая статистика, значения в столбцах мало варьируются, например, по цвету) – как решить?
	- **Устаревшая статистика** — оптимизатор может решить, что последовательное сканирование будет быстрее, если он не видит актуальную информацию о распределении данных. обновите статистику с помощью `ANALYZE`.
	- **Мало варьирующиеся значения** — для таких столбцов [[Индекс (Index)||индекс]] может быть неэффективен.
	- **Маленькие таблицы** — для маленьких [[Таблица БД (DB Table)||таблиц]] последовательное сканирование может быть быстрее.
	- **Некомпактные индексы** — оптимизируйте структуру [[Индекс (Index)||индекса]].
	- **Настройки конфигурации** — проверьте параметры базы данных, такие как `random_page_cost`.
- Как Postgres управляет [[Очистка PostgreSQL||очисткой]] и почему это важно для производительности базы данных?
	- PostgreSQL управляет очисткой через процесс [[Очистка PostgreSQL||autovacuum]], который автоматически удаляет устаревшие данные и восстанавливает пространство. 
	- Это важно для поддержания производительности, так как без очистки база может переполняться мертвыми строками, фрагментироваться и замедляться.
	- [[Очистка PostgreSQL||Autovacuum]] также обновляет статистику для оптимизации запросов, что помогает ускорить их выполнение.

##### Очень сложно

- Каковы преимущества и недостатки использования [[Оптимистичная Блокировка (Optimistic Locking)||оптимистической блокировки]]? В каких случаях [[Оптимистичная Блокировка (Optimistic Locking)||оптимистическая блокировка]] может быть бесполезной?
	- Приемущества:
		- Повышает производительность за счёт отсутствия блокировок на уровне базы данных.
		- Позволяет нескольким пользователям работать с данными без ожидания друг друга.
		- Эффективна, когда вероятность конфликтов низкая.
	- Недостатки:
		- При частых изменениях одних и тех же данных возможны конфликты.
		- Требует обработки ошибок и повторных попыток обновления.
		- Усложняет пакетные обновления из-за необходимости контроля версий.
	- Бесполезна когда:
		- Данные часто изменяются одновременно разными пользователями (система обработки заказов)
		- Требуется строгая согласованность и недопустимо работать с устаревшей версией (перевод денег)
		- Транзакции занимают много времени, увеличивая вероятность конфликтов (редактирование данных в форме)
- Каковы симптомы, указывающие на то, что пора [[Масштабирование Базы Данных||масштабировать базу данных]]?
	- Медленные запросы – особенно при росте данных.
	- Частые [[Блокировки (Locking)||блокировки]] и таймауты.
	- Высокая нагрузка на CPU, RAM или диск.
	- Сбои, падения, задержки [[Репликация (Replication)||репликации]].
	- Недостаток места или пропускной способности.
- Что такое [[Партиционирование (Секционирование, Partitioning)||DB partitioning]]? Как следует выбирать ключ [[Партиционирование (Секционирование, Partitioning)||партиционирование]]?
	- [[Партиционирование (Секционирование, Partitioning)]] = разделение таблицы базы данных на несколько частей (партиций) для улучшения производительности и управляемости.
	- Выбор ключа зависит от:
		- **Частоты запросов** – данные должны распределяться равномерно.
		- **Фильтров в запросах** – использовать колонку, часто встречающуюся в `WHERE`
		- **Типа партиционирования** – по диапазону (даты), хешу (равномерное распределение), списку (определённые значения).
- Какие структуры данных использует Postgres для [[Индекс (Index)||индексов]]?
	- [[B-Дерево (B-Tree)||B-Tree]] — по умолчанию. Для общего использования, эффективен для равенства и диапазонных запросов.
	- [[Хэш-таблица (Hash Table)||Hash]] — для поиска по точному совпадению (=).
	- GiST (Generalized Search Tree) — обобщенные деревья поиска. Для сложных типов данных, например, географических.
	- GIN (Generalized Inverted Index) — инвертированные списки. Для массивов, JSONB, полнотекстового поиска.
	- BRIN (Block Range INdexes) — индексирование диапазонов блоков. Для больших таблиц с естественной сортировкой.
	- SP-GiST (Space-Partitioned GiST) — деревья с разбиением пространства. Для многомерных данных (например, R-Tree).
- В чем разница между кластеризованными и некластеризованными индексами в Postgre?
	- Кластеризованный индекс = изменяет физический порядок строк в таблице, упорядочивая их по значению индекса. Каждая таблица может иметь только один кластеризованный индекс.
	- Некластеризованный индекс = не меняет порядок строк, а просто хранит указатели на строки. Таблица может иметь несколько некластеризованных индексов.
	- Главное различие = кластеризованный индекс меняет порядок данных в таблице, а некластеризованный — нет.
- Как бы вы проанализировали и оптимизировали медленные запросы в Postgres для приложения Java?
	1. Включить логирование медленных запросов в PostgreSQL с помощью `log_min_duration_statement`.
	2. Анализировать логи с инструментами, например, `pgBadger`, для поиска медленных запросов.
	3. Использовать [[Синтаксис EXPLAIN||EXPLAIN ANALYZE]] для анализа планов выполнения запросов.
	4. Оптимизировать запросы: добавьте [[Индекс (Index)||индексы]], обновите статистику (`ANALYZE`), исправьте соединения.
	5. Использовать параллельное выполнение для сложных запросов.
	6. Внедрить кеширование для часто запрашиваемых данных.
	7. Профилировать Java-приложение для поиска медленных запросов.
	8. Настроить [[Пул Соединений (Connection Pool)||пул соединений]] для оптимизации работы с базой данных.
	9. Регулярно мониторить производительность и проводить тестирование.
- Как Postgres обрабатывает механизмы [[Блокировки (Locking)||блокировки]] и как бы вы устраняли неполадки [[Deadlock||взаимоблокировок]] в приложении Java?
	1. Включить логирование `deadlock` в PostgreSQL.
	2. Обрабатывать исключение `SQLState 40P01` в Java и повторно выполнять [[Транзакция (Transaction)||транзакцию]].
	3. Избегать [[Deadlock||взаимоблокировок]], упорядочив запросы и используя таймауты.

---
## Core Java

##### Легко

- В чём разница между [[HashMap||HashMap]], [[HashTable||HashTable]] и [[ConcurrentHashMap||ConcurrentHashMap]]?
	- [[HashMap||HashMap]] = не синхронизирован, допускает `null` в ключах и значениях, быстрее, но не потокобезопасен.
	- [[HashTable||HashTable]] = синхронизирован, не допускает `null`, устаревший, медленнее из-за блокировки всего объекта.
	- [[ConcurrentHashMap||ConcurrentHashMap]] = потокобезопасен, но без полной блокировки, делит таблицу на сегменты, быстрее [[HashTable||HashTable]].
- Как работает [[Пул Литералов (String Pool, Literal Pool)||String Pool]] в Java? Почему [[String||String]] – [[Неизменяемый Объект (Immutable)||Immutable]]?
	- [[Пул Литералов (String Pool, Literal Pool)||Пул Литералов]] = область памяти, где хранятся уникальные строки. Повторные строки с одинаковым значением ссылаются на один и тот же объект.
	- [[String||Строки]] [[Неизменяемый Объект (Immutable)||неизменяемые]] потому, что содержимое строки нельзя изменить после создания, что повышает безопасность и эффективность.
- В чём разница между `==` и `equals()` в Java? Когда стоит переопределять `equals()` и `hashCode()`?
	- `==` сравнивает [[Ссылочный Тип Данных (Сильная Ссылка, Strong Reference, Link)||ссылки на объекты]], т.е. проверяет, указывают ли они на один и тот же объект в памяти.
	- `equals()` сравнивает содержимое объектов (если переопределён).
	- Переопределять `equals()` и `hashCode()` нужно, если объект используется в коллекциях типа [[HashMap||HashMap]] или [[HashSet||HashSet]] для корректного сравнения по значению при [[Коллизии при хэшировании (Hash Collision)||коллизии хэш-кодов]].
- Какие существуют [[Модификаторы Доступа (Access Modifiers)||модификаторы доступа]] в Java? Как они работают с наследованием?
	- [[public||public]] – доступен из любого места. Доступ к членам родительского класса с модификатором `public` возможен как в самом классе, так и в любом его наследнике.
	- [[protected||protected]] – доступен в пакете и в подклассах. Доступ к членам с модификатором `protected` возможен в наследуемом классе, даже если наследник находится в другом пакете.
	- [[private||private]] – доступен только внутри класса. Члены с модификатором `private` недоступны в дочерних классах, даже если они находятся в том же пакете или являются наследниками.
	- [[default (Модификатор Доступа по Умолчанию, Пакетная Видимость, Package-Private)||default]] (без модификатора) – доступен только в пределах своего пакета. Члены с доступом по умолчанию (`package-private`) доступны только в пределах того же пакета, как для наследников, так и для других классов этого пакета. В других пакетах доступ невозможен.

##### Средне

- В чём разница между [[Heap (Область Памяти)||heap]] и [[Stack (Область Памяти)||stack]] памятью?
	- [[Stack (Область Памяти)||Stack (стек)]] = используется для хранения вызовов методов, локальных переменных и [[Ссылочный Тип Данных (Сильная Ссылка, Strong Reference, Link)||ссылок на объекты]]. Память освобождается автоматически при выходе из метода ([[Стек (Stack)||LIFO]]).
	- [[Heap (Область Памяти)||Heap (куча)]] = используется для хранения [[Объект (Object)||объектов]]. Управляется [[Сборщик Мусора (Garbage Collector)||Garbage Collector]]. [[Объект (Object)||Объекты]] живут дольше, чем локальные переменные.
- Чем [[volatile||vilotile]] отличается от [[Синхронизация Потоков (synchronized)||synchronized]]?
	- [[volatile||volatile]] гарантирует видимость изменений переменной между [[Поток (Thread)||потоками]], но не обеспечивает [[Атомарность (Atomacy)||атомарность]] операций.
	- [[Синхронизация Потоков (synchronized)||synchronized]] обеспечивает и видимость, и [[Атомарность (Atomacy)||атомарность]], но требует [[Блокировки (Locking)||блокировки]], что может снизить производительность.
- Для чего используется [[transient||transient]]? Когда его следует использовать?
	- [[transient||transient]] в Java используется для исключения полей из процесса [[Сериализация (Serialization)||сериализации]]. Если поле помечено [[transient||transient]], оно не будет сохранено при [[Сериализация (Serialization)||сериализации объекта]].
	- Использовать [[transient||transient]] следует, когда:
		- Поле содержит чувствительные данные (например, пароли).
		- Поле [[{TODO} Кэш (Cache)||кэшируемое]] и может быть восстановлено заново.
		- Поле не является [[Сериализация (Serialization)||сериализуемым]] (например, [[Поток (Thread)||Thread]] или [[{TODO} Сокет (Socket)||Socket]]).
- В чём разница между [[ArrayList||ArrayList]] и [[LinkedList||LinkedList]]? Приведите примеры использования обоих.
	- [[ArrayList||ArrayList]] = автоматически расширяемый индексируемый [[Массив (Array)||массив]] объектов. Использование: когда важен быстрый доступ по индексу и частые чтения. Список товаров (быстро получаем по индексу), хранение постов в соцсети (быстро получаем по индексу).
	- [[LinkedList||LinkedList]] = [[Двусвязный список (Doubly Linked List)||двусвязный список]] [[Объект (Object)||объектов]]. Использование: когда часто вставляют/удаляют элементы в середине. История действий (вперёд-назад по узлам), менеджер задач (постоянное добавление/удаление).
- В чём разница между [[CompletableFuture||CompletableFuture]] и [[Future (интерфейс)||Future]]? Как использовать [[CompletableFuture||CompletableFuture]] для асинхронного программирования?
	- [[Future (интерфейс)||Future]] — это [[Интерфейс (Interface)||интерфейс]] для асинхронных задач, предоставляющий методы для получения результата вычисления, которое может завершиться в будущем. Основные методы — `get()` и `cancel()`.
	- [[CompletableFuture||CompletableFuture]] — это расширение [[Future (интерфейс)||Future]], которое позволяет дополнительно управлять асинхронными задачами, предоставляя возможность завершать задачи вручную, а также объединять несколько асинхронных операций с помощью методов, таких как `thenApply()`, `thenCompose()` и `whenComplete()`.
	- Для асинхронного программирования с [[CompletableFuture||CompletableFuture]]:
		- Создаёте задачу с помощью `CompletableFuture.supplyAsync()` или `CompletableFuture.runAsync()`.
		- Используете методы для комбинирования и обработки результатов (например, `thenApply()`).
		- Ожидаете завершения с помощью `join()` или `get()`.

##### Сложно

- Как создать [[Неизменяемый Объект (Immutable)||immutable]] класс?
	- Сделай поля [[private||private]] и [[final||final]].
	- Не предоставляй сеттеры – изменение состояния извне должно быть невозможно.
	- Инициализируй все поля в конструкторе.
	- Возвращай [[Глубокое Копирование (Deep Copy)||копии]] изменяемых объектов, если [[Класс (Class)||класс]] их содержит.
	- Запрети наследование ([[final||final]] [[Класс (Class)||class]]).
- Как устроена [[Java Memory Model||модель памяти в Java]]?
	- Java Memory Model (JMM) определяет, как [[Поток (Thread)||потоки]] взаимодействуют с памятью при работе с переменными. Предотвращает [[Гонки Данных (Data Races)||гонки данных]] и обеспечивает кроссплатформенную предсказуемость [[Многопоточное Программирование (Многопоточка, Multithreading)||многопоточного]] кода.
	- Принципы:
		- Разделение памяти – есть основная (heap, метод area) и потоки с локальными стековыми переменными.
		- [[volatile||Volatile]] – гарантирует чтение/запись сразу в основную память, минуя кеши потоков.
		- [[Синхронизация Потоков (synchronized)||Synchronized]] и [[Локи (Locks)||locks]] – обеспечивают [[Атомарность (Atomacy)||атомарность]], видимость изменений и упорядоченность.
		- [[Happens Before||Happens-before]] – определяет корректный порядок операций между [[Поток (Thread)||потоками]].
- Как работает [[Сборщик Мусора (Garbage Collector)||Garbage Collectior]]? Какие виды [[Сборщик Мусора (Garbage Collector)||Garbage Collector]] существуют в Java?
	- [[Сборщик Мусора (Garbage Collector)||Сборщик мусора]] автоматически освобождает память, удаляя [[Объект (Object)||объекты]], на которые больше нет [[Ссылочный Тип Данных (Сильная Ссылка, Strong Reference, Link)||ссылок]]. Это предотвращает [[Утечка Памяти (Memory Leak)||утечки памяти]] и снижает необходимость ручного управления памятью.
	- Типы:
		- [[Serial GC||Serial GC]] – однопоточный, подходит для небольших приложений.
		- [[Parallel GC||Parallel GC]] – многопоточный, используется по умолчанию в старых версиях Java.
		- [[G1 GC||G1 (Garbage First) GC]] – сбалансированный между паузами и производительностью, используется по умолчанию с [[{TODO} Java 9||Java 9]].
		- [[ZGC||ZGC]] – с минимальными паузами, подходит для больших [[Heap (Область Памяти)||heap’ов]] (до терабайтов).
		- [[Shenandoah GC||Shenandoah GC]] – низкие паузы за счёт параллельного освобождения памяти.


---
## Spring

Easy:
- What is Spring Boot and how does it differ from the standart Spring Framework?
- Explain the concept of auto-configuration in Spring boot. How does Spring Boot knows which configurations to apply?
- What is the application context? What does the lifecycle of a Spring Boot Application look like?
- What is the purpose of @PathVariable and @RequestParam annotations? How do they differ?

Medium:
- How many servlets are un the Spring Application?
- How to enable/disable logging of a particular class in Spring Application?
- What is the purpose of profiles in Spring Boot? How do you activate a profile?
- How do you handle exceptions in a Spring Boot Application? Provide an example using @ControllerAdvice or @ExceptionHandler
- How can you configure multiple data sources in a Spring Boot Application?
- What is lazy initialization in Spring Boot and how can you manage it in JPA relationships?
- Explain the difference between Authentication and Authorization in the context of Spring Security. 

Difficult:
- What is AOP? What are the use cases of using aspects in spring application?
- How do you handle transactions in Spring Boot? Explain the use of @Transactional. Explain the «read-only» and «timeout» parameters of transactional annotation.
- How will 1000 http reuests (sent at the same time) be handled in spring application with default configuration – all in parallel or sequentially?
- How does Spring Boot handle CORS? Can you configure it for your application?
- What are some common ways to secure REST APIs in Spring Boot?
- What is the purpose of the @PreAuthorize and @PostAuthorize annotations in Spring Security?
- How do you implement OAuth2 authentication in a Spring Boot application?

---
## Concurrency

Easy:
- What do you understand about Thread Priority?
- Which is more preffered – synchronised method or synchronized block
- What is ThreadLocal?

Medium:
- What is a Vilotile Field and What Guarantees Does Java Hold for Such field?
- Which of the following Operations are Atomic?
	- writing to a non-vilotile int;
	- writing to a vilotile int;
	- writing to a non-vliotilale long;
	- writing to a vliotilale long;
	- incrementing a vilotile long;

- Why Thread sleep() and yield() methods are static?
- What is Race Condition?
- [[CAS (Compare-And-Swap)||What is CAS (Compare and Swap)]]
- What are the differences between the synchronized keyword and explicid locks (like ReentrantLock)?
- Explain if that code is thread safe and if not – why?

```
public class Controller {
	private int i;
	
	@PostMapping(value = «»test»»)
	void m() {
		i++;
	}
}
```

Difficult:
- If two threads call a synchronized method on different object instances simultaneously, could one of these threads block? What if the method is static?
- What are the Available Implementations of ExecutorService in the Standart library?
- Describe the conditions of Deadlock, livelock and Starvation. Describe the possible causes of these conditions.
- Explain Java’s ForkJoinPool. How does it differ from ThreadPoolExecutor?
- What are some common concurrency isuues in Java and how would you prevent them?
- What is Happens-Before?

---
## Design patterns

Easy:
- [[SOLID]]
- GRASP

Medium:
- ACID
- At least 2 of the GOF patterns and explain their meaning

Hard:
- CQRS – what is it?

Difficult:
- What is SAGA pattern and how to use it properly?
- CAP theorem
- What is event sourcing?
- What is transactional outbox? How to do it? What is the purpose?

---
## Networking

Easy:
- What are the HTTP and HTTPS?
- Compare TCP and UDP

Medium:
- http1.1(rest) vs 2(2 way) vs 3(quick)
- What is firewall?
- What is websocket and what is it’s purpose? List examples for which use cases it may be relevant
- What is DNS?

Difficult:
- What happens when you enter [google.com](http://google.com) in wht web browser?
- What is protobuf? Ever worked with it?
- GRPC

---
## Microservices

Easy:
- How independent micre-services comunicate with each other?
- What is an Idmpotence and where it’s used?

Medium:
- Campare Monolithic SOA and Microservices – Microservices
- What are the bottlenecks of working with microservices?
- When monoliths are better?

Difficult:
- Distributed Transaction. What problems can they produce?

---
## Kafka

Easy:
- What is Apache Kafka? What are the primary use cases?
- What is a Kafka topic? 
- How does partitioning work? Why partitioning is important?
- What is Kafka offset? How does it managed for consumers?

Medium:
- How would you design a system using Kafka to ensure message ordering across partitions?
- How would you serialize and deserialize messages in Kafka using Java? Compare StringSerializer, JsonSerializer and Avro
- What is a consumer group in Kafka? How does it enable parallel consumption?

Hard:
- What factors impact Kafka throughput and latency? How would you optimize Kafka perfomance?
- What are Kafka’s ISR (In-Sync Replicas) and their role in insuring durability?
- Explain how to scale Kafka producers and consumers for a high-throughput application
- What are Kaffka connect and it’s role in integrating Kafka with other systems?

Difficult:
- What is the purpose of Kafka’s replication feature? How does it ensure fault tolerance?
- What are the differences between Kafka and traditional message queues like RabbitMQ or ActiveMQ?
- What is the role of a producer in Kafka and how does it ensure message delivery reliability?
- What are the key configurations for a Kafka producer in Java?
- How does a Kafka consumer handle offset management? What are the differences between auto-commit and manual offset management?
- What is the purpose of Kafka Streams and how does it differ from standart consumers?
- Explain the difference between «all-at-once», «at-most-once» and «exactly-once» delivery semantics in Kafka

---
## Design questions

- Let’s assume we have a task to call some external API, for example to perform identity verification of a client. We need to build an integration with 3rd party from scratch. Each API call costs us money. What are the most important things you would do to make sure it works correctly? What should be considered first?
- How would you design the account deposit/withdrawal feature high level in micreservice architecture where you have payment and core service running independently with their own databases. What locking mechanisms to use and how to coordinate interservice communication?

---
## Memory Management

- What is Java Memory Model? Describe purpose and basic ideas.
- What «Stop-The-World» means?
- When does an object become eligible for garbage collection? Describe how the GC collects an eligible object
- What is stored in heap and stack memories?
- What spacial guerentees Does the JMM hold for final fiels of a class?

---
## Cultural Fit

- How would you give feedback to a teammate who made a mistake which caused you to work extra hours?
- Describe when you faced a technical problem you couldn’t solve immediateley. What steps did you take to find a solution?
- How wave you handled a situation where you were under a lot of pressure to solve a technical problem?
- Can you share an instance where your team faced a significant technical problem? How did you contribute to the solution?
- Describe a time when you had to collaborate with a colleague who had a different approach to problem-solving. How did you handle it?
- Can you share an example of a technical project where you had to make a critical decision? How did you evaluate your options?
- Can you share a time when a project did not go as planned and you had to change your approach midway?
- How do you keep yourself updated with the latest advancements in your field?
- How have you adapted to a significant change at work, such as new software or change in team structure?
- Describe a time when you had to jiggle multiple tasks at once. How did you ensure everything got done?
- Can you tell me about a time when a project’s deadline changed suddenly? How did you adjust your plans?
- Describe a time when a tech project didn’t go as planned. How did you managed your stress?
- Tell me about the time when you had to work under a lot of pressure. What was going on and how did you handle it?

---

## Coding Tasks

library

  

Sufficient level:

6. TDD

7. thread safe code

8. corner cases

9. would be nice to add new books to library

Advanced level:

10. fair queue

11. improve concurrency

a. maybe cas

12. concurrency scope

a. book level

i. if we have a lot of books - too many locks

b. other criteria for lock

i. buckets, hash, genre

  

2 ?

  

Sufficient level:

13. logging should not block our app

14. log delivery

a. all should be persisted

b. can we skip something

15. should not produce a lot of garbage

a. avoid OOk

16. s o u r c e c o d e

a. base classes like here

17. separate thread for persist to file. Working thread safe code.

Advanced level:

We have a lot of logs and we want to process them more quickly.

18. thread safe size bounded queue

a. overflow queue - block or discard

19. batch persist with configs batch.size and timeout

20. ring buffer instead of queue

  

elevator

  

Sufficient level:

21. TDD

22. implementation of 2 user actions

a . r e q u e s t E l e v a t o r

b . s e n d E l e v a t o r

23. thread safe implementation

a. synchronized or lock

24. corner case handling

Advanced level:

25. fair request queue

26. we want to have possibility not to block on class level

a. more concurrent approaches

b. lock by elevator ?? TODO

---

  






  

**Screenshot 17, 18, 19, 20 (Interview test)**

Databases:

- group by, having
- explain
- indexes
- index exist but not used
- transactions
- isolation level
- optimistic lock
- pessimistic lock
- replication
- how to do partitioning
- how to do sharding

ORM:

- N + 1
- cache levels

Data Structures:

- tree - search - complexity
- balanced tree
- hashtable - O(1) and details
- collision resolution
- recursion
- tail recursion
- lock free approach
- bloom filter

Concurrency:

- rest execution concurrency
- servlet container

```
I++ task:

private int i;

  

@PostMapping(value = "test")

void m(){

    i++;

}
```

- not thread safe
- atomic
- sync + volatile
- the same order for sync, fair locks
- util.locks
- happens before
- thread pools, fork join feature

Garbage Collection:

- ZGC, Shenandoah
- G1GC
- latency and STW
- how to see it
- stack vs heap
- escape analysis

Profiling:

- jprofiler
- visualvm
- async profiler
- JFR
- heap dump
- thread dump example
- safepoint bias code example
- sampling vs instrumenting

Spring:

- AOP 
- AOP proxy self execution

Containers:

- docker
- dockerfile
- docker vs virtual machine vs bare metal
- k8s
- kubectl

- deploy update
- go into containre
- port forward

- ci/cd

Kafka:

- topic, partition, broker
- ordering
- parallelism
- delivery semantics

- exactly once is possible?
- at least one

- Producer semantics

- acks
- batches

Security:

- how to store password
- secure api (https)
- encryption vs hashing
- symmetric encryption
- asymmetric encryption
- how https works
- certificates, authority
- keystore, truststore
- how to sign request

Newtworks:

- tcp udp
- websockets
- dns
- protobuf
- grpc
- http 1.1(rest) vs 2(2 way) vs 3(quick)

Design patterns:

- saga
- cqrs
- event sourcing
- transactional outbox
- circuit breaker
- GOF
- SOLID
- GRASP

Algorythms:

- what sorting is used in Java?
- quick sort, merge sort

- complexity
- best case
- worst case
- adwantages

- LSM why rocks, tarantool so fast

Tasks:

- Let’s assume we have a task to call some external API, for example to perform identity verification of a client. We need to build an integration with 3rd party from scratch. Each API call costs us money. What are the most important things you would do to make sure it works correctly? What should be considered first?

  

**Screenshot 21, 22**

  

Theory part = 45-60 min

Coding part = 45 - 60 min

  

Theory:

To start a conversation, it's always interesting to learn what the person has been doing over the past year or two. This is the most relevant experience worth di

Once the person shares their story, review our list of topics and questions, select the ones that align with their described experience, and try to assess how di

understand the subject and how well they are understand it. Do not turn the interview into a question-and-answer session; give the person an opportunity to t

what they have done.

During the theoretical discussion, you should preliminary assess the person's level of knowledge. If you believe their knowledge level is insufficient, there is n

conducting a coding interview, and the interview can be stopped.

  

Coding:

How to start coding interview

› How to start coding interview details

Requirements:

27. Minimum; the first and minimal requirement is that the person must write a fully functional solution along with tests for it. It should run, execute, and g

Even if it operates in single-threaded mode or is not optimized, it must have a clear interface and work correctly.

28. Middle: the person must understand where multi threading issues can arise and should be able to pinpoint the exact lines of their code that need to t

They should write thread-safe code, regardless of how it is achieved - whether by using a single synchronized keyword or concurrent collections. If

thread-safe, the task is considered complete.

29. High: the solution must be optimized for maximum performance, minimizing or completely eliminating locks to ensure the highest possible throughp

approaches the person can propose to achieve this, the better.

After the interview push code to dev/name_surname branch (for history and analysis)

  
  

