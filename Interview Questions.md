## Data structures

##### Легко

- В чём разница между [[Стек (Stack)||Стеком]] и [[Очередь (Queue)||Очередью]]?
	- [[Стек (Stack)||Стек]] = первым пришёл — последним ушёл
	- [[Очередь (Queue)||Очередь]] = первым пришёл — первым ушёл
- В чём разница между [[Односвязный список (Singly Linked List)||Однонаправленным]] и [[Двусвязный список (Doubly Linked List)||Двунаправленым списком]]?
	- [[Односвязный список (Singly Linked List)||Однонаправленный]] = ссылка только на следующий элемент
	- [[Двусвязный список (Doubly Linked List)||Двунаправленный]] = ссылка на предыдущий и на следующий элементы
- В чём разница между [[Куча (Heap)||Кучей]] и [[Стек (Stack)||Стеком]]?
	- [[Стек (Stack)||Стек]] = это структура данных типа LIFO, где элементы добавляются и удаляются только с вершины; используется для временного хранения, например, в стеке вызовов
	- [[Куча (Heap)||Куча]] = это [[Дерево (Tree)||дерево]], где элементы упорядочены по приоритету (минимум или максимум), и применяется для задач с очередями приоритетов и алгоритмов графов
	- Главная разница: [[Стек (Stack)||стек]] ориентирован на последовательный доступ, а [[Куча (Heap)||куча]] — на управление приоритетами

##### Средне

- Сравните алгоритмы сортировки [[Сортировка слиянием (Merge Sort)||Слиянием]] и [[Быстрая сортировка (Quick Sort)||Быструю Сортировку]]. Какая лучше?
	- [[Сортировка слиянием (Merge Sort)||Сортировка Cлиянием]] = гарантированное $O(n \log n)$ для всех случаев + $O(n)$ для хранения отсортированного подмассива.
	- [[Быстрая сортировка (Quick Sort)||Быстрая Сортировка]] = $O(n \log n)$ – в лучшем и $O(n²)$ – в худшем + $O(\log n)$ на хранение рекурсии. 
	- Ответ: для гарантированной производительности без худших случаев – Слиянием, для ограниченной памяти – Быстрая. 
- В чём разница между [[HashMap]] и [[TreeMap]]?
	- [[HashMap]] = основан на [[Хэш-таблица (Hash Table)||хэш-таблице]], обеспечивает быстрый доступ к элементам ($O(1)$ в среднем случае), но не сохраняет порядок ключей. Подходит для задач, где важна производительность, а порядок не имеет значения.
	- [[TreeMap]] = использует красно-чёрное дерево, хранит ключи в отсортированном порядке (по возрастанию или с использованием [[{TODO} Comparable (интерфейс)||Comparator]]) и имеет сложность операций $O(\log n)$. Его выбирают, когда требуется упорядоченность элементов.
- Какая сложность у [[TreeMap]]?
	- Операции с [[TreeMap||TreeMap]], такие как вставка, удаление и поиск элементов, имеют сложность $O(\log n)$
- В чём разница между HashMap и ConcurrentHashMap? 
	- [[HashMap||HashMap]] = Не потокобезопасен. Подходит для использования в одном потоке. При доступе из нескольких потоков требуется внешняя синхронизация.
	- [[ConcurrentHashMap]] = Потокобезопасен. Подходит для использования в многопоточной среде. Использует механизм сегментации (или шардирования) для уменьшения блокировок, что позволяет нескольким потокам работать с картой одновременно.
- В чём разница между [[Двоичное Дерево (Binary Tree)||Двоичным деревом]] и [[Двоичное Дерево Поиска (Binary Search Tree)||Двоичным Деревом Поиска]]?
	- [[Двоичное Дерево (Binary Tree)||Двоичное Дерево]] = два потомка у каждого узла
	- [[Двоичное Дерево Поиска (Binary Search Tree)||Двоичное Дерево Поиска]] = значение левого потомка < значение родителя < значение правого потомка
- В каких случаях использовать [[Двоичное Дерево (Binary Tree)||Двоичное Дерево]] вместо [[Двусвязный список (Doubly Linked List)||Двусвязного Списка]]?
	- [[Двоичное Дерево (Binary Tree)||Двоичное Дерево]] = когда нужно хранить данные в структурированном и иерархическом виде с быстрым доступом и поиском (например, для поиска по ключу). Оно эффективно для операций вставки, удаления и поиска в среднем за $O(\log n)$ времени.
	- [[Двусвязный список (Doubly Linked List)||Двусвязный Список]] =  полезен, когда важна простота добавления и удаления элементов в любом месте списка, без необходимости в быстрых поисках по ключу. Он идеально подходит для сценариев, где порядок элементов меняется динамически, а доступ по индексу не требуется.

##### Сложно

- Знаете ли вы какие-либо структуры данных, которые работают лучше, чем [[HashMap||HashMap]], в тех случаях, когда контроль использования памяти очень важен?
	- [[TreeMap]] — если нужен порядок, без авторасширения.
	- [[{TODO} LinkedHashMap||LinkedHashMap]] с ограничением — контролируйте размер вручную.
	- [[Префиксное дерево (Trie)||Trie]] — для эффективного хранения строк.
	- [[{TODO} Bloom Filter]] — для проверки существования без хранения данных.
- Какие есть методы разрешения [[Коллизии при хэшировании (Hash Collision)||коллизий]]?
	- **Открытая адресация** – хороша для компактности:
		- **Линейное пробирование**: поиск следующей свободной ячейки.
		- **Квадратичное пробирование**: поиск с квадратичным шагом.
		- **Двойное хэширование**: использование второй хэш-функции для шага.
	- **Цепочки (Chaining)** – в каждой ячейке хранится список элементов с одинаковым хэшом. Хороши для гибкости.
	- **Ре-хэширование** – увеличение размера таблицы и перерасчет хэшей.
	- **Куки-хэширование** – элемент может храниться в нескольких ячейках, при коллизии происходит вытеснение.
	- **Перфектное хэширование** – создается идеальная хэш-функция, исключающая коллизии.
- В каких случаях имеет смысл использовать самобалансирующиеся двоичные деревья поиска ([[AVL-дерево||AVL-дерево]] и [[Красно-чёрное дерево (Red-Black Tree)||Красно-Чёрное Дерево]])?
	- **Общая выгода:**
		- **Детерминированная сложность:** Всегда $O(\log n)$, независимо от порядка данных.
		- **Упорядоченность:** Подходит для работы с диапазонами и сортировкой.
		- **Гибкость:** Лучше [[Хэш-таблица (Hash Table)||хэш-таблиц]], если требуется сохранение порядка.
	- **Индексация в базах данных**
		- Свойство: Быстрый поиск, вставка, удаление ($O(\log n)$).
		- Почему: Данные всегда отсортированы, подходят для диапазонных запросов.
	- **Множества и словари**
		- **Свойство:** Упорядоченные ключи, уникальность.
		- **Почему:** Подходят для структур [[{TODO} TreeSet||TreeSet]] и [[TreeMap||TreeMap]], обеспечивая сортировку и быструю навигацию.
	- **Логи и временные метки**
		- **Свойство:** Упорядоченность для временных данных.
		- **Почему:** Быстро находят записи по диапазону (например, за конкретный день).
	- **Компиляторы**
		- **Свойство:** Быстрый доступ к идентификаторам.
		- **Почему:** Используются для таблиц символов с частым добавлением/поиском.
	- **Очереди с приоритетом**
		- **Свойство:** Хранение в порядке приоритетов.
		- **Почему:** Легче поддерживать упорядоченность, чем в [[Куча (Heap)||кучах]], для частых изменений.
- Знаете ли вы какие-нибудь готовые к использованию неблокирующие коллекции в Java? Какую базовую и внутреннюю стратегию они используют?
	- [[ConcurrentHashMap||ConcurrentHashMap]] – Неблокирующий потокобезопасный вариант [[Хэш-таблица (Hash Table)||хэш-таблицы]].
	- [[ConcurrentLinkedQueue]] – Неблокирующая очередь, основанная на связном списке.
	- [[ConcurrentLinkedDeque]] – Неблокирующая двунаправленная очередь.
	- [[CopyOnWriteArrayList]] – Потокобезопасный список, который копирует массив при каждой операции записи.
	- [[ConcurrentSkipListMap]] – потокобезопасная сортированная мапа, основанная на SkipList.
	- [[ConcurrentSkipListSet]] – потокобезопасное множество, основанное на [[ConcurrentSkipListMap]].
	- Atomic структуры – структуры данных, хранящие [[Атомики (Atomics)||атомики]] (например, [[AtomicIntegerArray]], [[AtomicReferenceArray]])

##### Очень сложно

- Какую структуру данных нужно использовать для создания [[{TODO} LRU (Least Recently Used)]] кэша?
	- Стандартное решение = [[Хэш-таблица (Hash Table)||Хэш-таблица]] + [[Двусвязный список (Doubly Linked List)||Двусвязный список]]
	- [[Хэш-таблица (Hash Table)||Хэш-таблица]] = для хранения данных и для быстрого поиска по ключу ($O(1)$). 
	- [[Двусвязный список (Doubly Linked List)||Двусвязный список]] = для хранения порядка использования элементов. 
- Какова временная сложность добавления нового узла в [[Двоичное Дерево (Binary Tree)||двоичное дерево]]?
	- Для [[Сбалансированное Дерево (Balanced Tree)||сбалансированных]] [[Двоичное Дерево (Binary Tree)||двоичных деревьев]] – высота сбалансированного дерева пропорциональна [[Логарифм||логарифму]] от числа узлов, и поиск места для вставки происходит за время $O(\log n)$, где $n$ — количество узлов в дереве.
	- Для несбалансированных двоичных деревьев (например, если дерево превращается в список при добавлении элементов) – $O(n)$ времени, где $n$ — количество узлов в дереве.
---
## Databases

##### Легко

- В чём разница между [[Первичный Ключ (Primary Key)||Primary Keys]], [[Уникальный Ключ (Unique Key)||Unique Keys]] и [[Внешний Ключ (Foreign Key)||Foreign Keys]]
	- [[Первичный Ключ (Primary Key)||Primary Key]] = Уникально идентифицирует запись, не допускает `NULL`, только один на таблицу.
	- [[Уникальный Ключ (Unique Key)||Unique Key]] = Обеспечивает уникальность значений, допускает `NULL`, можно иметь несколько.
	- [[Внешний Ключ (Foreign Key)||Foreign Key]] = Связывает таблицы, ссылается на первичный ключ другой таблицы.
- Напишите SQL-запрос для расчета количества активных сотрудников по отделам, если количество сотрудников в отделе >= 1. [[Синтаксис SELECT (FROM, WHERE, GROUP BY, HAVING, ORDER BY)||Синтаксис SELECT]] , [[Синтаксис COUNT]]
```sql
SELECT 
    department_id,
    COUN. (*) AS active_employee_count 
FROM 
    employees
WHERE 
    status = 'active'
GROUP BY 
    department_id
HAVING 
    COUNT(*) >= 1;
```

- Что такое [[Схема (Schema)||схемы (schemas)]] в СУБД и как они могут помочь организовать данные в многопользовательском приложении Java (multi-tenant Java application)?
	- [[Схема (Schema)||Схема]] = логическое пространство имен, которое группирует таблицы, индексы, представления и другие объекты.
	- Применение:
		- Изоляция данных – каждому клиенту выделяется отдельная схема (например, tenant1, tenant2).
		- Управление доступом – установление прав на уровне схем.
		- Масштабируемость – легкое добавление новых клиентов без влияния на существующих.
		- Удобство обслуживания – обновления и резервные копии выполняются для конкретного клиента.
- В чем разница между [[Таблица БД (Database Table, DB Table)||таблицей (table)]] и [[Представление (View)||представлением (view)]] в PostgreSQL? Как бы вы использовали каждый из них в приложении Java?
	- [[Таблица БД (Database Table, DB Table)||Таблица]] = физическая структура базы данных, в которой хранятся данные. Используйте таблицы для хранения и управления данными.
	- [[Представление (View)||Представление]] = логическая структура, представляющая собой результат запроса SQL. Используйте для агрегирования данных, ограничения доступа (например, предоставления данных только определенным пользователям), упрощения запросов или реализации бизнес-логики.


##### Средне

- Как СУБД обеспечивает соответствие [[ACID||ACID]] и почему это важно для транзакционных приложений Java?
	- Атомарность = транзакция выполняется полностью или откатывается. Защищает от частичных изменений данных.
	- Консистентность = данные остаются целостными, соблюдаются все ограничения ([[Внешний Ключ (Foreign Key)||внешние ключи]], [[Уникальный Ключ (Unique Key)||уникальность]] и т.п.)
	- Изолированность = параллельные транзакции не влияют друг на друга, предотвращая ошибки, например, [[Грязное Чтение (Dirty Read)||грязные чтения]].
	- Надёжность = данные сохраняются даже при сбоях (отключение электричества)
	- Java-приложения используют [[ACID||ACID]] для работы с базами через [[JPA (Java Persistence API)||JPA]]/[[{TODO} Hibernate||Hibernate]] или [[Спринг Фреймворк (Spring Framework)||Spring]], чтобы гарантировать надежность, особенно в критичных системах (банки, магазины, бронирования).
- С какими наиболее распространенными проблемами производительности сталкиваются разработчики при работе с [[Реляционные Базы Данных (Relational Database)||реляционной базой данных]], которая является [[Высокая Согласованность (Strong Consistency)||высокосогласованной]]? Почему они происходят?
	- Медленные записи: синхронизация данных между [[Репликация Базы Данных (Database Replication, DB Replication)||репликами]] замедляет операции записи.
	- Высокие задержки: синхронизация данных между узлами увеличивает время отклика.
	- Перегрузка сети: необходимость постоянного обмена данными между узлами снижает производительность.
	- Конфликты данных: при одновременных изменениях возникают дополнительные накладные расходы на разрешение конфликтов.
	- Низкая доступность: в случае сбоя системы нужно ждать восстановления согласованности, что снижает доступность.
- Почему добавление слишком большого количества [[Индекс (Index)||индексов]] плохо? Каковы узкие места этого?
	- Много индексов ухудшают производительность при вставке, обновлении и удалении данных, требуют больше памяти и увеличивают нагрузку на систему. 
	- Они могут замедлить запросы, так как база данных тратит время на обновление индексов. 
	- Важно оптимизировать их количество и тип под реальные нужды.
- Какие есть варианты гарантировать согласованность в базе данных, если несколько процессов записывают/читают в одну и ту же таблицу (строку)? Имеет ли значение уровень изоляции базы данных?
	- Блокировки:
		- [[Пессимистичная Блокировка (Pessimistic Locking)]] = Процесс блокирует строку или таблицу для других, пока не завершит свою операцию.
		- [[Оптимистичная Блокировка (Optimistic Locking)]] = Процесс пытается выполнить операцию, и если кто-то изменил данные, то процесс проверяет и повторяет попытку.
	- [[Транзакция (Transaction)||Транзакции]] = Все изменения происходят в рамках транзакции, что гарантирует, что данные будут либо изменены полностью, либо не изменены вовсе.
	- [[Уровни Изоляции Транзакций (Transaction Isolation Levels)||Уровни изоляции транзакций]]:
		- [[Read Committed]] = Можно читать только подтвержденные данные, но возможны проблемы с параллельными изменениями.
		- [[Repeatable Read]] = Защищает от изменений, которые могут быть сделаны другими процессами.
		- [[Serializable]] = Гарантирует полную изоляцию между транзакциями, но снижает производительность.
- Какие уровни изоляции транзакций вы знаете? Как вы думаете, почему их так много?
	- [[Read Uncommitted||Read Uncommitted]]: позволяет читать неподтвержденные данные.
	- [[Read Committed||Read Committed]]: позволяет читать только зафиксированные данные.
	- [[Repeatable Read||Repeatable Read]]: предотвращает повторяющиеся чтения.
	- [[Serializable||Serializable]]: самый строгий уровень, транзакции выполняются последовательно, предотвращает все проблемы, но снижает производительность.
	- Причина = баланс между производительностью и консистентностью.
- Какой уровень изоляции по умолчанию для транзакций в Postgres?
	- [[Read Committed||Read Committed]]: позволяет читать только зафиксированные данные.
- Объясните разницу между [[Пессимистичная Блокировка (Pessimistic Locking)||пессемистической]] и [[Оптимистичная Блокировка (Optimistic Locking)||оптимистической]] блокировкой в ​​Postgres.
	- [[Пессимистичная Блокировка (Pessimistic Locking)||Пессимистическая блокировка]] захватывает блокировки на данные сразу, чтобы предотвратить их изменение другими транзакциями, что может привести к задержкам.
	- [[Оптимистичная Блокировка (Optimistic Locking)||Оптимистическая блокировка]] не захватывает блокировки заранее, а проверяет изменения данных в конце [[Транзакция (Transaction)||транзакции]], и если данные изменены, [[Транзакция (Transaction)||транзакция]] [[Откат Транзакции (Rollback)||откатывается]], что более эффективно при низкой вероятности конфликтов.
- Какова цель [[Синтаксис EXPLAIN||EXPLAIN и EXPLAIN ANALYSE]] в Postgres? Как они помогают оптимизировать запросы?
	- EXPLAIN = показывает план выполнения запроса, включая оценку затрат на операции, что помогает выявить неэффективные участки.
	- EXPLAIN ANALYSE = выполняет запрос и отображает реальные данные о времени выполнения и количестве обработанных строк, позволяя точнее оценить производительность запроса.
- Что такое [[Пул Соединений (Connection Pool)||пул соединений]] и как бы вы реализовали его с помощью таких инструментов, как HikariCP с Postgres в приложении Java? 
	- [[Пул Соединений (Connection Pool)||Пул соединений (Connection Pool)]] = механизм для повторного использования заранее созданных соединений с базой данных, что снижает накладные расходы на установление новых соединений.
	- HikariCP = это быстрый и эффективный [[Пул Соединений (Connection Pool)||пул соединений]] для Java. Для его использования с PostgreSQL нужно настроить HikariDataSource с параметрами подключения ([[URL (Uniform Resource Locator)||URL]], имя пользователя, пароль) и задать параметры пула (например, максимальное количество соединений и тайм-ауты). HikariCP автоматически управляет соединениями, что повышает производительность и уменьшает нагрузку на систему.
- Что такое [[Материализированное Представление (Materialized View)||материализованные представления]] в Postgres и чем они отличаются от [[Представление (View)||обычных представлений]]?
	- [[Представление (View)||View]] = это виртуальная таблица, основанная на SQL-запросе, данные в которой обновляются при каждом запросе.
	- [[Материализированное Представление (Materialized View)||Materialized View]] = это физическая копия данных, созданная на основе SQL-запроса, которая хранится на диске.

##### Сложно

- Что такое [[Шардинг (Sharding)||шардинг]]? В каких случаях следует выбирать [[Шардинг (Sharding)||шардинг]] вместо [[Партиционирование (Секционирование, Partitioning)||партиционирования]]?
	- [[Шардинг (Sharding)||Шардинг]] = разделение данных между несколькими независимыми серверами для горизонтального масштабирования и распределения нагрузки. Если данные не помещаются на одном сервере, нужна масштабируемость.
	- [[Партиционирование (Секционирование, Partitioning)||Партиционирование]] = логическое разделение данных внутри одной базы для оптимизации запросов. Если данные можно хранить на одном сервере, нужна локальная оптимизация.
- В каких случаях база данных может выбрать [[Последовательное Сканирование (Sequential Scan)||sequential scan]], даже если для таких критериев есть соответствующий индекс? (устаревшая статистика, значения в столбцах мало варьируются, например, по цвету) – как решить?
	- **Устаревшая статистика** — оптимизатор может решить, что последовательное сканирование будет быстрее, если он не видит актуальную информацию о распределении данных. обновите статистику с помощью `ANALYZE`.
	- **Мало варьирующиеся значения** — для таких столбцов [[Индекс (Index)||индекс]] может быть неэффективен.
	- **Маленькие таблицы** — для маленьких [[Таблица БД (Database Table, DB Table)||таблиц]] последовательное сканирование может быть быстрее.
	- **Некомпактные индексы** — оптимизируйте структуру [[Индекс (Index)||индекса]].
	- **Настройки конфигурации** — проверьте параметры базы данных, такие как `random_page_cost`.
- Как Postgres управляет [[Очистка PostgreSQL||очисткой]] и почему это важно для производительности базы данных?
	- PostgreSQL управляет очисткой через процесс [[Очистка PostgreSQL||autovacuum]], который автоматически удаляет устаревшие данные и восстанавливает пространство. 
	- Это важно для поддержания производительности, так как без очистки база может переполняться мертвыми строками, фрагментироваться и замедляться.
	- [[Очистка PostgreSQL||Autovacuum]] также обновляет статистику для оптимизации запросов, что помогает ускорить их выполнение.

##### Очень сложно

- Каковы преимущества и недостатки использования [[Оптимистичная Блокировка (Optimistic Locking)||оптимистической блокировки]]? В каких случаях [[Оптимистичная Блокировка (Optimistic Locking)||оптимистическая блокировка]] может быть бесполезной?
	- Приемущества:
		- Повышает производительность за счёт отсутствия блокировок на уровне базы данных.
		- Позволяет нескольким пользователям работать с данными без ожидания друг друга.
		- Эффективна, когда вероятность конфликтов низкая.
	- Недостатки:
		- При частых изменениях одних и тех же данных возможны конфликты.
		- Требует обработки ошибок и повторных попыток обновления.
		- Усложняет пакетные обновления из-за необходимости контроля версий.
	- Бесполезна когда:
		- Данные часто изменяются одновременно разными пользователями (система обработки заказов)
		- Требуется строгая согласованность и недопустимо работать с устаревшей версией (перевод денег)
		- Транзакции занимают много времени, увеличивая вероятность конфликтов (редактирование данных в форме)
- Каковы симптомы, указывающие на то, что пора [[Масштабирование Базы Данных||масштабировать базу данных]]?
	- Медленные запросы – особенно при росте данных.
	- Частые [[Блокировки (Locking)||блокировки]] и таймауты.
	- Высокая нагрузка на CPU, RAM или диск.
	- Сбои, падения, задержки [[Репликация Базы Данных (Database Replication, DB Replication)||репликации]].
	- Недостаток места или пропускной способности.
- Что такое [[Партиционирование (Секционирование, Partitioning)||DB partitioning]]? Как следует выбирать ключ [[Партиционирование (Секционирование, Partitioning)||партиционирование]]?
	- [[Партиционирование (Секционирование, Partitioning)]] = разделение таблицы базы данных на несколько частей (партиций) для улучшения производительности и управляемости.
	- Выбор ключа зависит от:
		- **Частоты запросов** – данные должны распределяться равномерно.
		- **Фильтров в запросах** – использовать колонку, часто встречающуюся в `WHERE`
		- **Типа партиционирования** – по диапазону (даты), хешу (равномерное распределение), списку (определённые значения).
- Какие структуры данных использует Postgres для [[Индекс (Index)||индексов]]?
	- [[B-Дерево (B-Tree)||B-Tree]] — по умолчанию. Для общего использования, эффективен для равенства и диапазонных запросов.
	- [[Хэш-таблица (Hash Table)||Hash]] — для поиска по точному совпадению (=).
	- GiST (Generalized Search Tree) — обобщенные деревья поиска. Для сложных типов данных, например, географических.
	- GIN (Generalized Inverted Index) — инвертированные списки. Для массивов, JSONB, полнотекстового поиска.
	- BRIN (Block Range INdexes) — индексирование диапазонов блоков. Для больших таблиц с естественной сортировкой.
	- SP-GiST (Space-Partitioned GiST) — деревья с разбиением пространства. Для многомерных данных (например, R-Tree).
- В чем разница между кластеризованными и некластеризованными индексами в Postgre?
	- Кластеризованный индекс = изменяет физический порядок строк в таблице, упорядочивая их по значению индекса. Каждая таблица может иметь только один кластеризованный индекс.
	- Некластеризованный индекс = не меняет порядок строк, а просто хранит указатели на строки. Таблица может иметь несколько некластеризованных индексов.
	- Главное различие = кластеризованный индекс меняет порядок данных в таблице, а некластеризованный — нет.
- Как бы вы проанализировали и оптимизировали медленные запросы в Postgres для приложения Java?
	1. Включить логирование медленных запросов в PostgreSQL с помощью `log_min_duration_statement`.
	2. Анализировать логи с инструментами, например, `pgBadger`, для поиска медленных запросов.
	3. Использовать [[Синтаксис EXPLAIN||EXPLAIN ANALYZE]] для анализа планов выполнения запросов.
	4. Оптимизировать запросы: добавьте [[Индекс (Index)||индексы]], обновите статистику (`ANALYZE`), исправьте соединения.
	5. Использовать параллельное выполнение для сложных запросов.
	6. Внедрить кеширование для часто запрашиваемых данных.
	7. Профилировать Java-приложение для поиска медленных запросов.
	8. Настроить [[Пул Соединений (Connection Pool)||пул соединений]] для оптимизации работы с базой данных.
	9. Регулярно мониторить производительность и проводить тестирование.
- Как Postgres обрабатывает механизмы [[Блокировки (Locking)||блокировки]] и как бы вы устраняли неполадки [[Взаимная блокировка (Deadlock)||взаимоблокировок]] в приложении Java?
	1. Включить логирование `deadlock` в PostgreSQL.
	2. Обрабатывать исключение `SQLState 40P01` в Java и повторно выполнять [[Транзакция (Transaction)||транзакцию]].
	3. Избегать [[Взаимная блокировка (Deadlock)||взаимоблокировок]], упорядочив запросы и используя таймауты.

---
## Core Java

##### Легко

- В чём разница между [[HashMap||HashMap]], [[HashTable||HashTable]] и [[ConcurrentHashMap||ConcurrentHashMap]]?
	- [[HashMap||HashMap]] = не синхронизирован, допускает `null` в ключах и значениях, быстрее, но не потокобезопасен.
	- [[HashTable||HashTable]] = синхронизирован, не допускает `null`, устаревший, медленнее из-за блокировки всего объекта.
	- [[ConcurrentHashMap||ConcurrentHashMap]] = потокобезопасен, но без полной блокировки, делит таблицу на сегменты, быстрее [[HashTable||HashTable]].
- Как работает [[Пул Литералов (String Pool, Literal Pool)||String Pool]] в Java? Почему [[String||String]] – [[Неизменяемый Объект (Immutable)||Immutable]]?
	- [[Пул Литералов (String Pool, Literal Pool)||Пул Литералов]] = область памяти, где хранятся уникальные строки. Повторные строки с одинаковым значением ссылаются на один и тот же объект.
	- [[String||Строки]] [[Неизменяемый Объект (Immutable)||неизменяемые]] потому, что содержимое строки нельзя изменить после создания, что повышает безопасность и эффективность.
- В чём разница между `==` и `equals()` в Java? Когда стоит переопределять `equals()` и `hashCode()`?
	- `==` сравнивает [[Ссылочный Тип Данных (Сильная Ссылка, Strong Reference, Link)||ссылки на объекты]], т.е. проверяет, указывают ли они на один и тот же объект в памяти.
	- `equals()` сравнивает содержимое объектов (если переопределён).
	- Переопределять `equals()` и `hashCode()` нужно, если объект используется в коллекциях типа [[HashMap||HashMap]] или [[HashSet||HashSet]] для корректного сравнения по значению при [[Коллизии при хэшировании (Hash Collision)||коллизии хэш-кодов]].
- Какие существуют [[Модификаторы Доступа (Access Modifiers)||модификаторы доступа]] в Java? Как они работают с наследованием?
	- [[public||public]] – доступен из любого места. Доступ к членам родительского класса с модификатором `public` возможен как в самом классе, так и в любом его наследнике.
	- [[protected||protected]] – доступен в пакете и в подклассах. Доступ к членам с модификатором `protected` возможен в наследуемом классе, даже если наследник находится в другом пакете.
	- [[private||private]] – доступен только внутри класса. Члены с модификатором `private` недоступны в дочерних классах, даже если они находятся в том же пакете или являются наследниками.
	- [[default (Модификатор Доступа по Умолчанию, Пакетная Видимость, Package-Private)||default]] (без модификатора) – доступен только в пределах своего пакета. Члены с доступом по умолчанию (`package-private`) доступны только в пределах того же пакета, как для наследников, так и для других классов этого пакета. В других пакетах доступ невозможен.

##### Средне

- В чём разница между [[Heap (Область Памяти)||heap]] и [[Stack (Область Памяти)||stack]] памятью?
	- [[Stack (Область Памяти)||Stack (стек)]] = используется для хранения вызовов методов, локальных переменных и [[Ссылочный Тип Данных (Сильная Ссылка, Strong Reference, Link)||ссылок на объекты]]. Память освобождается автоматически при выходе из метода ([[Стек (Stack)||LIFO]]).
	- [[Heap (Область Памяти)||Heap (куча)]] = используется для хранения [[Объект (Object)||объектов]]. Управляется [[Сборщик Мусора (Garbage Collector)||Garbage Collector]]. [[Объект (Object)||Объекты]] живут дольше, чем локальные переменные.
- Чем [[volatile||vilotile]] отличается от [[Синхронизация Потоков (synchronized)||synchronized]]?
	- [[volatile||volatile]] гарантирует видимость изменений переменной между [[Поток (Thread)||потоками]], но не обеспечивает [[Атомарность (Atomacy)||атомарность]] операций.
	- [[Синхронизация Потоков (synchronized)||synchronized]] обеспечивает и видимость, и [[Атомарность (Atomacy)||атомарность]], но требует [[Блокировки (Locking)||блокировки]], что может снизить производительность.
- Для чего используется [[transient||transient]]? Когда его следует использовать?
	- [[transient||transient]] в Java используется для исключения полей из процесса [[Сериализация (Serialization)||сериализации]]. Если поле помечено [[transient||transient]], оно не будет сохранено при [[Сериализация (Serialization)||сериализации объекта]].
	- Использовать [[transient||transient]] следует, когда:
		- Поле содержит чувствительные данные (например, пароли).
		- Поле [[Кэш (Cache)||кэшируемое]] и может быть восстановлено заново.
		- Поле не является [[Сериализация (Serialization)||сериализуемым]] (например, [[Поток (Thread)||Thread]] или [[Сокет (Socket)||Socket]]).
- В чём разница между [[ArrayList||ArrayList]] и [[LinkedList||LinkedList]]? Приведите примеры использования обоих.
	- [[ArrayList||ArrayList]] = автоматически расширяемый индексируемый [[Массив (Array)||массив]] объектов. Использование: когда важен быстрый доступ по индексу и частые чтения. Список товаров (быстро получаем по индексу), хранение постов в соцсети (быстро получаем по индексу).
	- [[LinkedList||LinkedList]] = [[Двусвязный список (Doubly Linked List)||двусвязный список]] [[Объект (Object)||объектов]]. Использование: когда часто вставляют/удаляют элементы в середине. История действий (вперёд-назад по узлам), менеджер задач (постоянное добавление/удаление).
- В чём разница между [[CompletableFuture||CompletableFuture]] и [[Future (интерфейс)||Future]]? Как использовать [[CompletableFuture||CompletableFuture]] для асинхронного программирования?
	- [[Future (интерфейс)||Future]] — это [[Интерфейс (Interface)||интерфейс]] для асинхронных задач, предоставляющий методы для получения результата вычисления, которое может завершиться в будущем. Основные методы — `get()` и `cancel()`.
	- [[CompletableFuture||CompletableFuture]] — это расширение [[Future (интерфейс)||Future]], которое позволяет дополнительно управлять асинхронными задачами, предоставляя возможность завершать задачи вручную, а также объединять несколько асинхронных операций с помощью методов, таких как `thenApply()`, `thenCompose()` и `whenComplete()`.
	- Для асинхронного программирования с [[CompletableFuture||CompletableFuture]]:
		- Создаёте задачу с помощью `CompletableFuture.supplyAsync()` или `CompletableFuture.runAsync()`.
		- Используете методы для комбинирования и обработки результатов (например, `thenApply()`).
		- Ожидаете завершения с помощью `join()` или `get()`.

##### Сложно

- Как создать [[Неизменяемый Объект (Immutable)||immutable]] класс?
	- Сделай поля [[private||private]] и [[final||final]].
	- Не предоставляй сеттеры – изменение состояния извне должно быть невозможно.
	- Инициализируй все поля в конструкторе.
	- Возвращай [[Глубокое Копирование (Deep Copy)||копии]] изменяемых объектов, если [[Класс (Class)||класс]] их содержит.
	- Запрети наследование ([[final||final]] [[Класс (Class)||class]]).
- Как устроена [[Java Memory Model||модель памяти в Java]]?
	- Java Memory Model (JMM) определяет, как [[Поток (Thread)||потоки]] взаимодействуют с памятью при работе с переменными. Предотвращает [[Гонки Данных (Data Races)||гонки данных]] и обеспечивает кроссплатформенную предсказуемость [[Многопоточное Программирование (Многопоточка, Multithreading)||многопоточного]] кода.
	- Принципы:
		- Разделение памяти – есть основная (heap, метод area) и потоки с локальными стековыми переменными.
		- [[volatile||Volatile]] – гарантирует чтение/запись сразу в основную память, минуя кеши потоков.
		- [[Синхронизация Потоков (synchronized)||Synchronized]] и [[Локи (Locks)||locks]] – обеспечивают [[Атомарность (Atomacy)||атомарность]], видимость изменений и упорядоченность.
		- [[Happens Before||Happens-before]] – определяет корректный порядок операций между [[Поток (Thread)||потоками]].
- Как работает [[Сборщик Мусора (Garbage Collector)||Garbage Collectior]]? Какие виды [[Сборщик Мусора (Garbage Collector)||Garbage Collector]] существуют в Java?
	- [[Сборщик Мусора (Garbage Collector)||Сборщик мусора]] автоматически освобождает память, удаляя [[Объект (Object)||объекты]], на которые больше нет [[Ссылочный Тип Данных (Сильная Ссылка, Strong Reference, Link)||ссылок]]. Это предотвращает [[Утечка Памяти (Memory Leak)||утечки памяти]] и снижает необходимость ручного управления памятью.
	- Типы:
		- [[Serial GC||Serial GC]] – однопоточный, подходит для небольших приложений.
		- [[Parallel GC||Parallel GC]] – многопоточный, используется по умолчанию в старых версиях Java.
		- [[G1 GC||G1 (Garbage First) GC]] – сбалансированный между паузами и производительностью, используется по умолчанию с [[{TODO} Java 9||Java 9]].
		- [[ZGC||ZGC]] – с минимальными паузами, подходит для больших [[Heap (Область Памяти)||heap’ов]] (до терабайтов).
		- [[Shenandoah GC||Shenandoah GC]] – низкие паузы за счёт параллельного освобождения памяти.


---
## Spring

##### Легко

- Что такое [[Spring Boot||Spring Boot]] и как он отличается от стандартного [[Спринг Фреймворк (Spring Framework)||Spring Framework]]?
	- [[Спринг Фреймворк (Spring Framework)||Spring Framework]] = базовый спринг
	- [[Spring Boot||Spring Boot]] = [[Спринг Фреймворк (Spring Framework)||Spring Framework]] + навароты для быстрого развёртывания приложений:
		- [[Автоконфигурация (Spring Boot Auto Configuration)||Автоконфигурация]]: автоматически настраивает приложение на основе найденных зависимостей, минимизируя потребность в ручной настройке.
		- [[{TODO} Сервер Приложений (Application Server)||Встроенные серверы]]: поддержка встроенных серверов (Tomcat, Jetty, Undertow), что позволяет запускать приложение без внешнего сервера.
		- [[{TODO} Spring Boot Starter||Spring Boot Starter]]: набор шаблонов зависимостей, которые упрощают добавление стандартных библиотек в проект.
		- [[{TODO} Spring Boot Actuator||Spring Boot Actuator]]: интеграция позволяющая легко добавлять функции [[Мониторинг (Monitoring)||мониторинга]], метрик и управления приложением.
		- [[{TODO} Spring Initializr||Spring Initializr]]: готовые проекты для различных типов приложений ([[Микросервис (Microservice)||микросервисы]], [[Веб Приложение (Web Application)||веб-приложения]] и т.д.)
- Что такое [[Автоконфигурация (Spring Boot Auto Configuration)||авто-конфигурация]] в [[Spring Boot||Spring Boot]]? Как [[Spring Boot||Spring Boot]] понимает какую конфигурацию применить?
	- [[Автоконфигурация (Spring Boot Auto Configuration)||Авто-конфигурация]] = механизм, который автоматически настраивает [[Бин (Spring Bean)||бины Spring]] на основе зависимостей в [[Classpath||classpath]] и свойств в `application.properties` / `application.yml`
	- Применяется на основе:
		- **Classpath scanning** — проверяет, какие [[{TODO} Библиотека (Library)||библиотеки]] подключены.
		- **[[{TODO} Conditional (аннотация)||@ConditionalOn..]]. аннотации** — активируют [[Бин (Spring Bean)||бины]] только при выполнении условий.
		- `spring.factories / META-INF/spring/org.springframework.boot.autoconfigure.AutoConfiguration.imports` — содержит список [[Автоконфигурация (Spring Boot Auto Configuration)||авто-конфигураций]], которые [[Spring Boot||Spring Boot]] загружает при старте.
- Что такое [[Контекст Приложения (Application Context)||Application Context]]? Как выглядит жизненный цикл [[Spring Boot||Spring Boot]] приложения?
	- [[Контекст Приложения (Application Context)||Application Context]] = центральный интерфейс [[Контейнер Инверсии Контроля в Спринг (Spring IoC Container)||контейнера в Spring]], который управляет [[Жизненный Цикл Бина (Bean Life Cycle)||жизненным циклом бинов]], зависимостями и конфигурацией приложения. Он предоставляет доступ к [[Бин (Spring Bean)||бинам]], ресурсам, событиям и другим функциям.
	- Жизненный цикл Spring Boot приложения:
		- **Запуск** (SpringApplication.run()) — инициализация [[Контекст Приложения (Application Context)||ApplicationContext]], сканирование компонентов.
		- **Создание и настройка [[Бин (Spring Bean)||бинов]]** — внедрение зависимостей, обработка аннотаций ([[{TODO} Component (аннотация)||@Component]], [[{TODO} Service (аннотация)||@Service]], [[{TODO} Bean (аннотация)||@Bean]] и др.).
		- **Готовность приложения** — запуск встроенного [[Веб Сервер (Web Server)||веб-сервера]] (если используется), обработка запросов.
		- **Завершение работы** — вызов [[{TODO} PreDestroy (аннотация)||@PreDestroy]], [[{TODO} DisposableBean||DisposableBean]], освобождение ресурсов перед остановкой.
- Для чего существуют аннотации [[{TODO} PathVariable (аннотация)||@PathVariable]] и [[{TODO} RequestParam (аннотация)||@RequestParam]]? Чем они отличаются?
	- [[{TODO} PathVariable (аннотация)||@PathVariable]] = ожидаемый параметр в GET запросе (в [[URL (Uniform Resource Locator)||URL]]).
	- [[{TODO} RequestParam (аннотация)||@RequestParam]] = ожидаемый параметр в [[POST||POST]] запросе (в [[Тело HTTP запроса (HTTP Request Body)||body]]).

##### Средне

- Сколько [[Сервлет (Servlet)||сервлетов]] в [[Спринг Фреймворк (Spring Framework)||Spring]] приложении?
	- В [[Спринг Фреймворк (Spring Framework)||Spring]]-приложении обычно один [[Сервлет (Servlet)||сервлет]] — [[DispatcherServlet||DispatcherServlet]].
- Как включить/выключить логи конкретного класса в [[Спринг Фреймворк (Spring Framework)||Spring]] приложении?
	- В `application.properties` / `application.yml`:
```properties
logging.level.com.example.MyClass=DEBUG  # Включить  
logging.level.com.example.MyClass=OFF    # Выключить  
```
- В `logback.xml`:
```xml
<logger name="com.example.MyClass" level="DEBUG"/>
<logger name="com.example.MyClass" level="OFF"/>
```
- В `log4j2.xml`:
```xml
<Logger name="com.example.MyClass" level="DEBUG"/>
<Logger name="com.example.MyClass" level="OFF"/>
```
Через [[{TODO} Spring Boot Actuator||Actuator]]:
```bash
curl -X POST "http://localhost:8080/actuator/loggers/com.example.MyClass" -H "Content-Type: application/json" -d '{"configuredLevel": "DEBUG"}'
```
- Зачем нужны [[Spring Boot Profile||профили]] в [[Spring Boot||Spring Boot]]? Как активировать профиль?
	- [[Spring Boot Profile||Spring Boot профили]] используются для управления конфигурацией приложения в разных средах (например, `dev`, `test`, `prod`). Они позволяют загружать специфичные настройки, например, [[База данных (БД, Database, DB)||базы данных]] или логирования.
	- Активировать профиль можно через:
		- Переменную среды: `SPRING_PROFILES_ACTIVE=prod`
		- Флаг [[Виртуальная Машина Java (Java Virtual Machine, JVM)||JVM]]: `-Dspring.profiles.active=prod`
		- `application.properties`: `spring.profiles.active=prod`
- Как обрабатывать исключения в [[Spring Boot||Spring Boot]] приложении? Приведите примеры с использованием [[ControllerAdvice (аннотация)||@ControllerAdvice]] или [[ExceptionHandler (аннотация)||@ExceptionHandler]].
	- В [[Spring Boot||Spring Boot]] для обработки [[Исключение (Exception)||исключений]] можно использовать [[ControllerAdvice (аннотация)||@ControllerAdvice]], чтобы централизованно перехватывать ошибки во всех контроллерах. Используя [[ExceptionHandler (аннотация)||@ExceptionHandler]], можно обрабатывать конкретные исключения, например:
```java
@ControllerAdvice
public class GlobalExceptionHandler {
	
    @ExceptionHandler(RuntimeException.class)
    public ResponseEntity<String> handleRuntimeException(RuntimeException ex) {
        return ResponseEntity.status(HttpStatus.INTERNAL_SERVER_ERROR)
                             .body("Ошибка: " + ex.getMessage());
    }
}
```
- Как использовать несколько источников данных в [[Spring Boot||Spring Boot]] приложении?
	- Конфигурация источников данных:
```java
@Bean(name = "primaryDataSource")
public DataSource dataSourcePrimary() {
    return DataSourceBuilder.create().build();
}

@Bean(name = "secondaryDataSource")
public DataSource dataSourceSecondary() {
    return DataSourceBuilder.create().build();
}
```
- Использование [[{TODO} Qualifier (аннотация)||@Qualifier]] в [[{TODO} Репозиторий (Repository)||репозиториях]]:
```java
@Repository
public class MyRepository {

    @Autowired
    @Qualifier("primaryDataSource")
    private DataSource dataSource;
}
```
- Конфигурация в `application.yml`:
```yaml
spring:
  datasource:
    primary:
      url: jdbc:mysql://localhost:3306/db1
    secondary:
      url: jdbc:mysql://localhost:3306/db2
```

- Что такое [[Ленивая Инициализация (Lazy Initialization)||ленивая инициализация в Spring Boot]] и как ей управлять в [[JPA (Java Persistence API)||JPA]] отношениях?
	- Ленивая инициализация (Lazy Initialization) в [[JPA (Java Persistence API)||JPA]] загружает связанные данные только при первом доступе. 
	- Чтобы управлять:
		- Используйте [[Transactional (аннотация)||@Transactional]] для работы в пределах транзакции.
		- Применяйте [[{TODO} EntityGraph (аннотация)||@EntityGraph]] для явной загрузки данных.
		- Для немедленной загрузки используйте [[{TODO} JPA Fetch Types||FetchType.EAGER]].
- Объясните разницу между [[Аутентификация (Authentication)||Аутентификацией]] и [[Авторизация (Authorization)||Авторизацией]] в контексте [[Spring Security||Spring Security]].
	- [[Аутентификация (Authentication)||Аутентификация]] = проверка личности пользователя (логин, пароль, [[{TODO} JWT||JWT]]). “Кто ты?”
	- [[Авторизация (Authorization)||Авторизация]] – проверка прав доступа (можно ли открыть страницу / выполнить действие). “Что тебе разрешено?”
	- В [[Spring Security||Spring Security]]:
		- [[Аутентификация (Authentication)||Аутентификация]] → AuthenticationManager, UserDetailsService.
		- [[Авторизация (Authorization)||Авторизация]] → @PreAuthorize, hasRole(), http.authorizeHttpRequests().


##### Сложно

- Что такое [[Аспектно-Ориентированное Программирование (AOP, Aspect Oriented Programming)||АОП]]? Как аспекты применяются в [[Спринг Фреймворк (Spring Framework)||Spring]] приложении?
	- [[Аспектно-Ориентированное Программирование (AOP, Aspect Oriented Programming)||AOP (Aspect-Oriented Programming)]] = парадигма программирования, разделяющая кросс-функциональные задачи от основной логики.
	- Применение в [[Спринг Фреймворк (Spring Framework)||Spring]] = использование аннотаций [[{TODO} Aspect (аннотация)||@Aspect]] для внедрения функциональности (например, логирования или транзакций) через прокси-объекты.
- Как обрабатывать [[Транзакция (Transaction)||транзакции]] в [[Spring Boot||Spring Boot]]? Расскажите про [[Transactional (аннотация)||@Transactional]]. Объясните для чего используются параметры «read-only» и «timeout» в [[Transactional (аннотация)||@Transactional]] аннотации. 
	- В [[Spring Boot||Spring Boot]] транзакции обрабатываются с помощью [[Transactional (аннотация)||аннотации @Transactional]], которая позволяет указать, что метод должен быть выполнен в рамках [[Транзакция (Transaction)||транзакции]].
	- Параметры:
		- **readOnly**: Устанавливает транзакцию как доступную только для чтения. Это может улучшить производительность, если данные не изменяются, так как [[База данных (БД, Database, DB)||база данных]] может оптимизировать выполнение запросов.
		- **timeout**: Устанавливает максимальное время ожидания для выполнения [[Транзакция (Transaction)||транзакции]]. Если [[Транзакция (Transaction)||транзакция]] не завершится вовремя, она будет отменена. 
- Как будут обработаны 1000 [[HTTP Запрос (HTTP Request)||запросов]], одновременно отправленных в [[Спринг Фреймворк (Spring Framework)||Spring]] приложение со стандартной конфигурацией: параллельно или последовательно?
	- Запросы будут обрабатываться параллельно, но ограничены количеством [[Поток (Thread)||потоков]] в [[Thread Pool||пуле]] [[Веб Сервер (Web Server)||веб-сервера]] (встроенного в [[Спринг Фреймворк (Spring Framework)||Spring]]). Если [[HTTP Запрос (HTTP Request)||запросов]] больше, чем доступных [[Поток (Thread)||потоков]], они будут ждать в [[Очередь (Queue)||очереди]].
- Как [[Spring Boot||Spring Boot]] работает с [[CORS||CORS]]? Можно ли настроить механизм работы?
	- **Аннотация [[CrossOrigin (аннотация)||@CrossOrigin]]** = используется для настройки [[CORS||CORS]] на уровне контроллеров или методов (например, `@CrossOrigin(origins = "http://example.com")`).
	- **Глобальная настройка** = осуществляется через реализацию `WebMvcConfigurer` и метод `addCorsMappings()`, где можно задать разрешенные источники и методы для всех эндпоинтов.
- Какие есть способы защиты [[REST (Representational State Transfer)||REST API]] в [[Spring Boot||Spring Boot]]?
	- [[Аутентификация (Authentication)||Аутентификация]] и [[Авторизация (Authorization)||авторизация]]:
		- [[{TODO} JWT||JWT]]
		- Basic Auth
		- [[OAuth 2.0||OAuth2]]
	- Защита от атак:
		- [[{TODO} CSRF (межсайтовая подделка запроса)||CSRF]] (для web-приложений)
		- [[CORS||CORS]] (для ограничений по доменам)
	- Шифрование данных: [[HTTPS (Hypertext Transfer Protocol Secure)||HTTPS]]/SSL/TLS для защиты передачи данных.
	- Ограничение скорости запросов = использование Rate Limiting (например, с Bucket4j или Resilience4j).
	- Фильтры и interceptor-ы = для [[Аутентификация (Authentication)||аутентификации]], логирования и проверки запросов.
	- Роли и разрешения = конфигурация ролей и прав доступа с помощью [[Spring Security||Spring Security]].
	- Защита от [[{TODO} SQL Инъекция (SQL Injection)||SQL инъекций]] = использование подготовленных выражений и [[Объектно-Реляционное Отображение (Object-Relational Mapping, ORM)||ORM]] ([[JPA (Java Persistence API)||JPA]]).
	- [[Логирование (Logging)||Логирование]] и [[Мониторинг (Monitoring)||мониторинг]] = логирование запросов и использование [[{TODO} Spring Boot Actuator||Spring Actuator]] для [[Мониторинг (Monitoring)||мониторинга]].
- Для чего существуют аннотации [[PreAuthorize (аннотация)||@PreAuthorize]] и [[PostAuthorize (аннотация)||@PostAuthorize]] в [[Spring Boot||Spring Boot]]?
	- [[PreAuthorize (аннотация)||@PreAuthorize]] = для проверки прав доступа до выполнения метода, предоставляя возможность ограничить доступ на основе выражений безопасности. 
	- [[PostAuthorize (аннотация)||@PostAuthorize]] = проверка прав доступа после выполнения метода, что позволяет принимать решения о доступе на основе результата выполнения метода.
- Как имплементировать [[Аутентификация (Authentication)||аутентификацию]] [[OAuth 2.0||OAuth2]] в [[Spring Boot||Spring Boot]] приложении?
	- Добавить зависимости в `pom`
```xml
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-oauth2-client</artifactId>
</dependency>
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-security</artifactId>
</dependency>
```
	- Настроить `application.yaml`
```yaml
spring:
  security:
    oauth2:
      client:
        registration:
          google:
            client-id: your-client-id
            client-secret: your-client-secret
            scope: profile, email
```
	- Создать конфигурацию [[Spring Security||Spring Security]]
```java
@Configuration
public class SecurityConfig {
    @Bean
    public SecurityFilterChain securityFilterChain(HttpSecurity http) throws Exception {
        http.authorizeHttpRequests(auth -> auth
                .requestMatchers("/", "/public").permitAll()
                .anyRequest().authenticated())
            .oauth2Login(oauth2 -> oauth2.defaultSuccessUrl("/welcome", true))
            .logout(logout -> logout.logoutSuccessUrl("/").permitAll());
        return http.build();
    }
}
```
	- Добавить [[{TODO} Контроллер (Controller)||контроллер]]
```java
@RestController
public class AuthController {
    @GetMapping("/welcome")
    public Map<String, Object> secured(@AuthenticationPrincipal OidcUser user) {
        return Map.of("name", user.getFullName(), "email", user.getEmail());
    }
}
```
	- Запустить

---
## Concurrency

##### Легко

- Как вы понимаете [[Приоритет Потока (Thread Priority)||Thread Priority]]?
	- Thread Priority = приоритет потока
	- Значения от 1 до 10 (стандартное – 5)
	- Не гарантирует реального приоритета. Это решают [[Виртуальная Машина Java (Java Virtual Machine, JVM)||JVM]] и [[{TODO} Операционная Система (ОС, Operating System, OS)||OS]]
- Что предпочтительнее: [[Синхронизация Потоков (synchronized)||synchronised]]-блок или [[Синхронизация Потоков (synchronized)||synchronised]]-метод?
	- Метод = для защиты всего метода от конкуренции, для простоты и понятности.
	- Блок = для синхронизации критической секции внутри метода, для тонкого повышения производительности.
- Что такое [[ThreadLocal||ThreadLocal]]?
	- [[ThreadLocal||ThreadLocal]] = механизм, позволяющий каждому [[Поток (Thread)||потоку]] хранить собственный экземпляр переменной. 

##### Средне

- Что такое [[volatile||volatile]] и какие гарантии даёт эта метка?
	- [[volatile||volatile]] = ключевое слово для видимости переменной в [[Многопоточное Программирование (Многопоточка, Multithreading)||многопоточной среде]].
	- Гарантии:
		- Видимость = если изменена одним [[Поток (Thread)||потоком]], то остальные видят. 
		- Запрет [[Кэш (Cache)||кэширования]] = всегда читается из основной памяти. 
		- Отсутствие [[Атомарность (Atomacy)||атомарности]] = не гарантирует атомарность
- Какие из следующих операций – [[Атомарность (Atomacy)||атомарные]]:
	- `запись в не-vilotile int;` = атомарно, если тип данных имеет размер, поддерживаемый процессором (например, 32-битный int).
	- `запись в vilotile int;` = не атомарно, поскольку [[volatile||volatile]] лишь указывает на возможное изменение значения из других потоков, не обеспечивая синхронизации.
	- `запись в не-vliotilale long;` = атомарно на 64-битных системах, но не гарантируется на 32-битных.
	- `запись в vliotilale long;` = не атомарно, поскольку [[volatile||volatile]] не гарантирует атомарности.
	- `инкремент vilotile long;` = не атомарно, поскольку операция инкремента включает чтение, изменение и запись значения.
- Почему методы `sleep()` и `yield()` класса [[Поток (Thread)||Thread]] – статические?
	- `sleep()` — приостанавливает выполнение текущего [[Поток (Thread)||потока]] на заданный промежуток времени.
	- `yield()` — передает управление другому [[Поток (Thread)||потоку]], если он готов к выполнению.
	- Статические, потому что они управляют текущим [[Поток (Thread)||потоком]], а не требуют создания экземпляра класса [[Поток (Thread)||Thread]]
- Что такое [[Состояние Гонки (Race Condition)||Состояние Гонки]]?
	- [[Состояние Гонки (Race Condition)||Состояние Гонки (Race Condition)]] = несколько [[Поток (Thread)||потоков]] одновременно пытаются получить доступ к общим данным или ресурсу, и результат зависит от порядка их выполнения.
- Что такое [[CAS (Compare-And-Swap)||CAS (Compare-And-Swap)]]?
	- [[CAS (Compare-And-Swap)||CAS]] = [[Атомарность (Atomacy)||атомарная]] операция, которая используется для безопасного изменения значения переменной в [[Многопоточное Программирование (Многопоточка, Multithreading)||многозадачных]] программах.
	- Алгоритм:
		- Проверяем, что текущее значение равно тому, что мы ожидаем.
		- Если да – меняем на новое. 
		- Если нет – ничего не меняем. 
- В чём разница между [[Синхронизация Потоков (synchronized)||synchronized]] и прямыми [[Локи (Locks)||локами]] (например, [[ReentrantLock||ReentrantLock]])?
	- [[Синхронизация Потоков (synchronized)||Synchronized]] =  простая низкоуровневая синхронизация, встроенная в язык Java, но с ограниченной гибкостью.
	- [[ReentrantLock||ReentrantLock]] = больше возможностей, таких как тайм-ауты и прерывание ожидания, и позволяет повторно захватывать блокировки.
- Потокобезопасен ли следующий код и почему?
  
```java
// Не потокобезопасен потому что:
// 1. i – не защищена синхронизацией или атомиком
// 2. i++ – не атомарна, в ней 3 шага (чтение -> увеличение -> запись)

public class Controller {
	private int i;
	
	@PostMapping(value = "test")
	void m() {
		i++;
	}
}

// Решение 1: Атомики

public class Controller {
	private AtomicInteger i = new AtomicInteger(0);
	
	@PostMapping(value = "test")
	void m() {
	    i.incrementAndGet();  // Атомарный инкремент
	}
}

// Решение 2: Синхронизация

public class Controller {
	private int i;
	
	@PostMapping(value = "test")
	synchronized void m() {
	    i++;
	}
}
```

##### Сложно

- Если два [[Поток (Thread)||потока]] вызывают [[Синхронизация Потоков (synchronized)||synchronized]]-метод на разных [[Объект (Object)||объектах]] одного [[Класс (Class)||класса]] одновременно, могут ли они друг друга заблокировать? Что если этот метод – [[static||статический]]?
	- Если метод не статический = нет. Блокировка действует на уровень [[Объект (Object)||объекта]], а у [[Поток (Thread)||потоков]] разные [[Объект (Object)||объекты]].
	- Если метод статический = да. Блокировка действует на уровень [[Класс (Class)||класса]], и [[Поток (Thread)||потоки]] будут ждать друг друга.
- Какие имплементации [[ExecutorService||ExecutorService]] доступны в стандартной библиотеке?
	- **ThreadPoolExecutor** – гибкий [[Thread Pool||пул потоков]], настраиваемый вручную.
	- **ScheduledThreadPoolExecutor** – поддерживает отложенные и периодические задачи.
	- Фабричные методы `Executors`:
		- `newFixedThreadPool(n)` – фиксированный пул.
		- `newCachedThreadPool()` – динамический пул.
		- `newSingleThreadExecutor()` – один поток.
		- `newScheduledThreadPool(n)` – планировщик задач.
		- `newSingleThreadScheduledExecutor()` – однотопоточный планировщик.
- Опишите условия возникновения [[Взаимная блокировка (Deadlock)||Deadlock]], [[Живая Блокировка (Livelock)||Livelock]] и [[Голодание (Starvation)||Starvation]]. Назовите возможные причины их возникновения.
	- [[Взаимная блокировка (Deadlock)||Deadlock (взаимная блокировка)]]:
		- Суть = ситуация, когда несколько [[Поток (Thread)||потоков]] ждут друг друга, чтобы освободился нужный ресурс, но никто его освободить не может.
		- Причина = каждый [[Поток (Thread)||поток]] держит один ресурс и ждет другой, создавая “замкнутый круг”.
	- [[Живая Блокировка (Livelock)||Livelock (ожившая блокировка)]]:
		- Суть = [[Поток (Thread)||потоки]] пытаются выйти из [[Взаимная блокировка (Deadlock)||взаимоблокировки]], но вместо прогресса бесконечно реагируют друг на друга, не продвигаясь дальше.
		- Причина = оба [[Поток (Thread)||потока]] пытаются избежать конфликта, но их действия приводят к бесконечному циклу (например, оба постоянно освобождают и запрашивают ресурс заново).
	- [[Голодание (Starvation)||Starvation (голодание)]]:
		- Суть = [[Поток (Thread)||поток]] не получает доступ к ресурсу, потому что другие [[Поток (Thread)||потоки]] с более высоким [[Приоритет Потока (Thread Priority)||приоритетом]] постоянно его перехватывают.
		- Причина = система управления ресурсами отдает приоритет одним [[Поток (Thread)||потокам]], игнорируя другие.
- Расскажите про [[ForkJoinPool||ForkJoinPool]]. Чем он отличается от [[ThreadPoolExecutor||ThreadPoolExecutor]]?
	- [[ForkJoinPool||ForkJoinPool]] = для задач, которые могут быть рекурсивно разделены на подзадачи, с оптимизацией через “work stealing” для эффективного распределения работы между [[Поток (Thread)||потоками]].
	- [[ThreadPoolExecutor||ThreadPoolExecutor]] = для общего управления [[Поток (Thread)||потоками]] с [[Очередь (Queue)||очередями]] задач, подходя для менее сложных задач и стабильного выполнения больших рабочих нагрузок.
- Какие частые проблемы с [[Многопоточное Программирование (Многопоточка, Multithreading)||многопоточностью]] возникают в Java и как их решать?
	- [[Состояние Гонки (Race Condition)||Состояние гонки (Race Condition)]]
		- **Проблема**: Несколько [[Поток (Thread)||потоков]] изменяют общие данные без [[Синхронизация Потоков (synchronized)||синхронизации]].
		- **Решение**: [[Синхронизация Потоков (synchronized)||synchronized]], [[ReentrantLock||ReentrantLock]], [[Атомики (Atomics)||Atomic-классы]], [[volatile||volatile]] (если нужна только видимость изменений).
	- [[Взаимная блокировка (Deadlock)||Взаимная Блокировка (Deadlock)]]
		- **Проблема**: [[Поток (Thread)||Потоки]] навсегда заблокированы из-за циклического ожидания ресурсов.
		- **Решение**: Фиксированный порядок блокировок, `tryLock()` с таймаутом.
	- [[Живая Блокировка (Livelock)||Живая Блокировка (Livelock)]]
		- **Проблема**: [[Поток (Thread)||Потоки]] не блокируются, но продолжают менять состояния, не выполняя полезной работы.
		- **Решение**: Рандомизация ожидания, отказ от агрессивных повторных попыток.
	- [[Голодание (Starvation)||Голодание (Starvation)]]
		- **Проблема**: [[Поток (Thread)||Поток]] не получает доступа к ресурсу из-за [[Приоритет Потока (Thread Priority)||приоритетов]] или блокировок.
		- **Решение**: Использование справедливых блокировок ([[ReentrantLock||ReentrantLock(true)]], [[{TODO} Честный Семафор (Fair Semaphore)||Fair Semaphore]]).
	- Неправильная видимость данных (Visibility Issue)
		- **Проблема**: [[Поток (Thread)||Потоки]] видят устаревшее состояние переменной.
		- **Решение**: [[volatile||volatile]], [[Синхронизация Потоков (synchronized)||synchronized]], [[Атомики (Atomics)||Atomic-классы]].
	- Разупорядочивание инструкций (Instruction Reordering)
		- **Проблема**: Оптимизация [[Виртуальная Машина Java (Java Virtual Machine, JVM)||JVM]] или процессора меняет порядок исполнения.
		- **Решение**: [[volatile||volatile]], [[Синхронизация Потоков (synchronized)||synchronized]], [[{TODO} MemoryBarrier||MemoryBarrier]] в Unsafe.
	- Ошибка публикации (Publication Issue)
		- **Проблема**: [[Объект (Object)||Объект]] доступен другим [[Поток (Thread)||потокам]] до полной инициализации.
		- **Решение**: Инициализация в конструкторе, [[volatile||volatile]], [[final||final]] поля.
	- Ожидание на изменяемом объекте (Mutable Object as [[Локи (Locks)||Lock]])
		- **Проблема**: Изменяемый объект используется как монитор блокировки.
		- **Решение**: [[final||final]] объекты для блокировок.
	- [[ThreadLocal||ThreadLocal]] Memory Leak
		- **Проблема**: [[Поток (Thread)||Потоки]] не освобождают [[ThreadLocal||ThreadLocal]]-данные, вызывая утечки памяти.
		- **Решение**: `remove()` после использования.
	- Проблемы с [[ForkJoinPool||ForkJoinPool]] и [[CompletableFuture||CompletableFuture]]
		- **Проблема**: [[Поток (Thread)||Потоки]] могут не завершаться или блокировать выполнение.
		- **Решение**: Ограничение числа [[Поток (Thread)||потоков]], `join()` вместо `get()`, `handle()` для исключений.
- Что такое [[Happens Before||Happens-Before]]?
	- [[Happens Before||Happens Before]] = правило, определяющее порядок выполнения операций в [[Многопоточное Программирование (Многопоточка, Multithreading)||многопоточности]] и гарантии их видимости.
	- Гарантии:
		- Последовательность в одном [[Поток (Thread)||потоке]] – код выполняется сверху вниз, без неожиданных перестановок.
		- Синхронизация ([[Синхронизация Потоков (synchronized)||synchronized]]) – выход из блока [[Синхронизация Потоков (synchronized)||synchronized]] одним потоком гарантирует, что другой [[Поток (Thread)||поток]], входя в этот блок, увидит актуальные данные.
		- [[volatile||volatile]] переменные – запись в [[volatile||volatile]] поле всегда видна всем [[Поток (Thread)||потокам]], читающим его после записи.
		- Запуск и завершение [[Поток (Thread)||потока]] – если [[Поток (Thread)||поток]] завершился, другие потоки, вызвавшие `Thread.join()`, увидят его изменения.
		- Использование [[Локи (Locks)||Lock]] – разблокировка [[Локи (Locks)||Lock]] одним [[Поток (Thread)||потоком]] делает изменения доступными для другого, который получит этот [[Локи (Locks)||Lock]].
		- Очереди (Executor, BlockingQueue) – передача данных через потокобезопасные очереди гарантирует, что потребитель увидит данные после их отправки.


---
## Design patterns

##### Легко:

- [[SOLID]]
	- [[Принцип Единственной Ответственности (Single Responsibility Principle, SRP)||Single-responsibility principle]] = [[Класс (Class)||класс]] должен иметь только одну причину для изменения.
	- [[Принцип Открытости-Закрытости (Opened-Closed Principle, OCP)||Open–closed principle]] = код должен быть открыт для расширения, но закрыт для модификации.
	- [[Принцип Подстановки Барбары Лисков (Liskov Substitution Principle, LSP)||Liskov substitution principle]] = [[Объект (Object)||объекты]] дочерних [[Класс (Class)||классов]] должны заменять [[Объект (Object)||объекты]] родительских без нарушения логики.
	- [[Принцип Разделения Интерфейсов (Interface Segregation Principle, ISP)||Interface segregation principle]] = клиенты не должны зависеть от [[Интерфейс (Interface)||интерфейсов]], которые они не используют.
	- [[Принцип Инверсии Зависимостей (Dependency Inversion Principle, DIP)||Dependency inversion principle]] = модули должны зависеть от [[Абстракция (Abstraction)||абстракций]], а не от конкретных реализаций.
- [[GRASP||GRASP]] = 9 принципов для правильного распределения обязанностей между [[Объект (Object)||объектами]] в [[ООП – Объектно-Ориентированное Программирование (OOP, Object Oriented Programming)||ООП]]. Принципы:
	- Expert = ответственность у [[Объект (Object)||объекта]] с нужной информацией.
	- Creator = [[Класс (Class)||класс]] создаёт [[Объект (Object)||объект]], если использует или агрегирует его.
	- Controller = промежуточный слой между UI и логикой.
	- [[Слабая Связность (Низкая Связность, Low Coupling)||Low Coupling (Низкая Связность)]] = меньше зависимостей между [[Класс (Class)||классами]].
	- [[Высокое Зацепление (High Cohesion)||High Cohesion (Высокое Зацепление)]] = [[Класс (Class)||класс]] выполняет связанные задачи.
	- [[Полиморфизм (Polymorphism)||Polymorphism]] = разные реализации через единый [[Интерфейс (Interface)||интерфейс]].
	- Pure Fabrication = отдельный [[Класс (Class)||класс]] для несвязанных обязанностей.
	- Indirection = посредник снижает [[Слабая Связность (Низкая Связность, Low Coupling)||связанность]].
	- Protected Variations = [[Абстракция (Abstraction)||абстракция]] защищает от изменений.

##### Средне:

- [[ACID||ACID]] = набор свойств транзакций, обеспечивающих их надёжность.
	- [[Атомарность (Atomacy)||Atomicity (Атомарность)]] = [[Транзакция (Transaction)||транзакция]] либо выполняется полностью, либо не выполняется вовсе, исключая промежуточные состояния.
	- [[Согласованность (Консистентность, Consistency)||Consistency (Согласованность)]] = после завершения [[Транзакция (Transaction)||транзакции]] данные остаются в целостном и допустимом состоянии.
	- [[Изолированность (Isolation)||Isolation (Изолированность)]] = параллельные [[Транзакция (Transaction)||транзакции]] не мешают друг другу и выполняются так, как если бы они шли последовательно.
	- [[Надёжность (Durability)||Durability (Надёжность)]] = успешно завершённые [[Транзакция (Transaction)||транзакции]] сохраняются в системе даже в случае сбоев.
- Назовите как минимум 2 [[Паттерны Банды Четырёх (Gang of Four Patterns, GOF Patterns)||GOF-паттерна]] и объясните их назначение. 
	- [[Строитель (Builder)||Строитель (Builder)]] – [[Порождающие паттерны (Creational Patterns)||порождающий паттерн]], который разделяет создание сложного [[Объект (Object)||объекта]] на шаги ([[StringBuilder||StringBuilder]]).
	- [[Наблюдатель (Observer)||Наблюдатель (Observer)]] – [[Поведенческие паттерны (Behavioral Patterns)||поведенческий паттерн]], который позволяет [[Объект (Object)||объекту]] уведомлять подписчиков об изменениях.
	- [[Адаптер (Adapter)||Адаптер (Adapter)]] – [[Структурные паттерны (Structural Patterns)||структурный паттерн]], который позволяет [[Объект (Object)||объектам]] с несовместимыми [[Интерфейс (Interface)||интерфейсами]] работать вместе.

##### Трудно:

- [[CQRS (Command Query Responsibility Segregation)||CQRS]] = [[{TODO} Архитектурные Паттерны (Architectural Patterns)||архитектурный паттерн]], который разделяет операции чтения и записи, используя разные модели данных для оптимизации производительности и масштабируемости системы.

##### Очень трудно:

- Паттерн [[Сага (SAGA)||SAGA]] и как правильно его применять?
	- [[Сага (SAGA)||SAGA]] = [[{TODO} Архитектурные Паттерны (Architectural Patterns)||архитектурный паттерн]] для управления [[Распределённая Транзакция (Distributed Transaction)||распределёнными транзакциями]], где каждая операция выполняется как отдельная локальная [[Транзакция (Transaction)||транзакция]], а в случае ошибки вызываются компенсирующие действия для отката изменений.
	- Как правильно применять:
		- Выбери подход:
			- [[Хореография (Choreography)||Хореография]] (через события) для масштабируемости
			- [[Оркестрация (Orchestration)||Оркестрация]] (через координатор) для контроля.
		- **Проработай откаты:** Каждая операция должна иметь компенсирующее действие на случай ошибки.
		- **Логируй состояние:** Следи за выполнением шагов, учитывай [[Идемпотентность (Idempotency)||идемпотентность]] для защиты от дубликатов.
		- **Делай операции независимыми:** Каждая локальная [[Транзакция (Transaction)||транзакция]] должна фиксироваться отдельно, без глобальных [[Блокировки (Locking)||блокировок]].
- [[КАП-теорема (CAP-theorem)||CAP теорема]] = в [[Распределённая Система (Distributed System)||распределённых системах]] при сетевых сбоях можно гарантировать только одно из трёх:
	- **Согласованность (Consistency)** — все серверы видят одинаковые данные.
	- **Доступность (Availability)** — система всегда доступна для чтения и записи.
	- **Терпимость к разделению (Partition tolerance)** — система работает даже в случае сбоя связи между серверами.
- [[Event Sourcing||Event Sourcing]] = [[{TODO} Архитектурные Паттерны (Architectural Patterns)||архитектурный паттерн]], при котором все изменения состояния системы сохраняются как неизменяемые события, а текущее состояние восстанавливается путём последовательного применения этих событий.
- [[Transactional Outbox||Transactional Outbox]] = это [[{TODO} Архитектурные Паттерны (Architectural Patterns)||архитектурный паттерн]], который сохраняет сообщения в отдельной [[Таблица БД (Database Table, DB Table)||таблице базы данных]] в рамках [[Транзакция (Transaction)||транзакции]], гарантируя, что сообщения будут отправлены только в случае успешного завершения [[Транзакция (Transaction)||транзакции]].

---
## Networking

##### Легко

- Что такое [[HTTP (Hypertext Transfer Protocol)||HTTP]] и [[HTTPS (Hypertext Transfer Protocol Secure)||HTTPS]]?
	- [[HTTP (Hypertext Transfer Protocol)||HTTP]] = протокол передачи данных в интернете, использующий текстовые запросы и ответы, но без шифрования.
	- [[HTTPS (Hypertext Transfer Protocol Secure)||HTTPS]] = безопасная версия [[HTTP (Hypertext Transfer Protocol)||HTTP]], которая шифрует передаваемые данные с помощью [[TLS (Transport Layer Security)||TLS]]/[[SSL (Secure Sockets Layer)||SSL]] для защиты от перехвата и подмены.
- Сравни [[TCP||TCP]] и [[UDP||UDP]]
	- [[TCP||TCP]] = обеспечивает надежную, упорядоченную передачу данных с проверкой ошибок, но работает медленнее из-за установления соединения и подтверждений.
	- [[UDP||UDP]] = передает данные быстрее, без гарантий доставки и порядка, что делает его идеальным для стриминга, онлайн-игр и VoIP.

##### Средне

- Сравните [[HTTP 1.1||HTTP 1.1]], [[HTTP 2||HTTP 2]] и [[HTTP 3||HTTP 3]]
	- [[HTTP 1.1||HTTP 1.1]] – работает по [[TCP||TCP]], использует отдельное соединение для каждого запроса.
	- [[HTTP 2||HTTP 2]] – все еще [[TCP||TCP]], но добавляет мультиплексирование (несколько запросов в одном соединении).
	- [[HTTP 3||HTTP 3]] – заменяет [[TCP||TCP]] на [[UDP||UDP]] + [[QUIC (Quick UDP Internet Connections)||QUIC]], что делает соединение мгновенным и устойчивым.
- [[Фаервол (Firewall)]] = это система безопасности, контролирующая и фильтрующая входящий и исходящий трафик в сети для защиты от несанкционированного доступа и атак.
- Что такое [[Веб-сокет (Websocket)||Websocket]] и зачем используется? Приведите примеры использования.
	- [[Веб-сокет (Websocket)||Websocket]] = протокол, позволяющий устанавливать постоянное двустороннее соединение между клиентом и [[Веб Сервер (Web Server)||сервером]] для обмена данными в реальном времени.
	- Используется:
		- **Чаты** – обеспечивают обмен сообщениями в реальном времени между пользователями.
		- **Игры** – позволяют синхронно передавать данные о движении игроков и событиях в игре. 
		- **Онлайн-банкинг** – [[Веб-сокет (Websocket)||сокеты]] обеспечивают мгновенные обновления о [[Транзакция (Transaction)||транзакциях]] и состоянии счетов без необходимости обновлять страницу.
- [[DNS (Domain Name System)||DNS]] = система, которая переводит человеко-понятные доменные имена (например, `www.example.com`) в [[IP Адрес (Internet Protocol Address, IP Address)||IP-адреса]].

##### Трудно

- Что происходит, когда мы вводим `google.com` в браузере?
	- Получение [[IP Адрес (Internet Protocol Address, IP Address)||IP-Адреса]] с помощью [[DNS (Domain Name System)||DNS]]
	- Установление соединения
		- [[TCP||TCP]] – для [[HTTP 1.1||HTTP 1.1]] и [[HTTP 2||HTTP 2]]
		- [[QUIC (Quick UDP Internet Connections)||QUIC]] – для [[HTTP 3||HTTP 3]] (на основе [[UDP||UDP]])
	- [[HTTPS (Hypertext Transfer Protocol Secure)||HTTPS]] соединение 
	- Отправление [[HTTP Запрос (HTTP Request)||HTTP запроса]]
	- Обработка [[HTTP Запрос (HTTP Request)||запроса]] [[Веб Сервер (Web Server)||сервером]], получение [[HTTP Ответ (HTTP Response)||ответа]]
	- Получение и рендеринг страницы
	- [[Кэш (Cache)||Кэширование]] – браузер проверяет, есть ли уже загруженные данные в локальном хранилище и использует их если возможно.
- [[Protobuf (Protocol Buffers)||Protobuf]] = бинарный формат сериализации данных от Google, который обеспечивает компактность, скорость и типизированный обмен данными между системами.
- [[gRPC (Google Remote Procedure Call)||gRPC]] = это фреймворк для взаимодействия между [[Микросервис (Microservice)||сервисами]], использующий [[Protobuf (Protocol Buffers)||Protobuf]] для сериализации данных и [[HTTP 2||HTTP/2]] для эффективной передачи.


---
## Microservices

##### Легко

- Как независимые [[Микросервис (Microservice)||микросервисы]] [[Взаимодействие Микросервисов (Interaction of Microservices)||взаимодействуют между собой]]?
	- Синхронно:
		- [[REST (Representational State Transfer)||REST (HTTP)]]
		- [[gRPC (Google Remote Procedure Call)||gRPC]]
	- Асинхронно:
		- [[Очередь Сообщений (Message Queue)||Очереди сообщений (Message Queues)]]
		- [[Event-Driven Architecture (EDA)||Event-Driven Architecture (EDA)]]
		- [[Издатель-Подписчик (Публикация-Подписка, Publish-Subscribe, Pub-Sub)||Публикация-подписка (Publish-Subscribe)]]
	- Инфраструктурные решения:
		- [[Служба Обнаружения и Маршрутизации (Обнаружение Сервисов, Service Discovery)||Службы обнаружения и маршрутизации (Service Discovery)]]
		- [[Service Mesh||Service Mesh]]
	- Управление API:
		- [[API Gateway||API Gateway]]
- Что такое [[Идемпотентность (Idempotency)||идемпотентность]] и где применяется?
	- [[Идемпотентность (Idempotency)||Идемпотентность]] = свойство операции, при котором её повторное выполнение не изменяет результат после первого выполнения.
	- Применение:
		- [[API (Application Programming Interface)||API]]: Позволяет безопасно повторно отправлять запросы без риска изменения данных.
		- Сетевые [[Протокол (Protocol)||протоколы]]: Обеспечивает корректное поведение при повторных попытках доставки пакетов.
		- [[Таблица БД (Database Table, DB Table)||Базы данных]]: Используется для обеспечения [[Согласованность (Консистентность, Consistency)||консистентности]] при повторных [[Транзакция (Transaction)||транзакциях]] или запросах.
		- [[Микросервис (Microservice)||Микросервисы]]: Помогает избежать дублирования действий при сбоях или повторных запросах от клиентов.
		- [[Очередь Сообщений (Message Queue)||Очереди сообщений]]: Гарантирует, что сообщение будет обработано только один раз, даже если оно отправляется несколько раз.

##### Средне

- Сравните [[Монолит (Monolith)||Монолит]], [[Сервисно-Ориентированная Архитектура (Service-Oriented Architecture, SOA)||SOA]] и [[Взаимодействие Микросервисов (Interaction of Microservices)||Микросервис – Микросервис]]
	- **[[Монолит (Monolith)||Монолит]]** = всё в одном приложении. Простота. Проблемы с масштабированием.
	- **[[Сервисно-Ориентированная Архитектура (Service-Oriented Architecture, SOA)||SOA]]** = крупные сервисы с [[Enterprise Service Bus (ESB)||ESB]]. Если нужна гибкость в масштабах компании. 
	- **[[Микросервис (Microservice)||Микросервисы]]** = маленькие независимые сервисы с [[API (Application Programming Interface)||API]]. Если важна [[Масштабирование (Скейлинг, Scaling)||масштабируемость]] и независимость команд. 
- Какие ботлнеки у [[Микросервис (Microservice)||микросервисов]]?
	- **Сеть** – задержки и потери пакетов, узкие места в пропускной способности.
	- **[[База данных (БД, Database, DB)||Базы данных]]** – перегрузка, конкуренция за ресурсы, сложность горизонтального [[Масштабирование (Скейлинг, Scaling)||масштабирования]].
	- **Сервисная координация** – избыточные [[HTTP Запрос (HTTP Request)||запросы]], задержки в межсервисных вызовах.
	- **Балансировка нагрузки** – неравномерное распределение трафика.
	- **[[Логирование (Logging)||Логирование]] и [[Мониторинг (Monitoring)||мониторинг]]** – сложность в трассировке [[HTTP Запрос (HTTP Request)||запросов]] (distributed tracing).
	- **[[Кэш (Cache)||Кэширование]]** – несогласованность данных, повышенная нагрузка на [[Кэш (Cache)||кэш-системы]].
	- **Автоматическое [[Масштабирование (Скейлинг, Scaling)||масштабирование]]** – задержка реакции на нагрузку, резкие скачки потребления ресурсов.
	- **Безопасность** – рост поверхности атаки из-за множества [[Микросервис (Microservice)||сервисов]].
- Когда лучше использовать [[Монолит (Monolith)||монолит]]?
	- Маленький проект или стартап, где важна скорость разработки.
	- Команда небольшая, и не требуется сложная архитектура.
	- Важно быстро разрабатывать и выпускать новые функции.
	- Нагрузки небольшие, и нет строгих требований к [[Масштабирование (Скейлинг, Scaling)||масштабируемости]].

##### Сложно

- Что такое [[Распределённая Транзакция (Distributed Transaction)||распределённая транзакция]] и какие проблемы она может создавать?
	- Распределённая транзакция = [[Транзакция (Transaction)||транзакция]], которая затрагивает несколько независимых ресурсов (например, [[База данных (БД, Database, DB)||базы данных]], [[Микросервис (Microservice)||микросервисы]], [[Брокер Сообщений (Message Broker)||брокеры сообщений]]) и требует механизма глобальной [[Согласованность (Консистентность, Consistency)||согласованности]], чтобы изменения применялись [[Атомарность (Atomacy)||атомарно]].
	- Проблемы:
		- **Производительность** – накладные расходы на согласование (например, [[Двухфазный Коммит (Two-Phase Commit, 2PC)||2PC]]).
		- **Задержки** – высокая латентность из-за сетевого взаимодействия.
		- **[[Согласованность (Консистентность, Consistency)||Консистентность]] данных** – сложность обеспечения [[ACID||ACID-свойств]] между сервисами.
		- **Распределённые сбои** – частичный отказ узлов может привести к подвешенным [[Транзакция (Transaction)||транзакциям]].
		- **Компенсационные механизмы** – необходимость сложной логики откатов ([[Сага (SAGA)||SAGA-паттерн]]).
		- **[[Масштабирование (Скейлинг, Scaling)||Скалируемость]]** – снижение горизонтального [[Масштабирование (Скейлинг, Scaling)||масштабирования]] из-за блокировок.
		- **Идентификация [[Транзакция (Transaction)||транзакции]]** – сложность корреляции операций между сервисами.

---
## Kafka

##### Легко

- Что такое [[Кафка (Apache Kafka)||Apache Kafka]]? Для чего его применяют?
	- [[Кафка (Apache Kafka)||Apache Kafka]] = распределённая платформа потоковой обработки и [[Брокер Кафка (Kafka Broker)||брокер сообщений]], предназначенный для передачи, хранения и обработки данных в реальном времени
	- Применяют для [[Логирование (Logging)||логирования]], обработки событий, [[Взаимодействие Микросервисов (Interaction of Microservices)||интеграции микросервисов]], передачи сообщений между сервисами и потоковой аналитики.
- [[Топик Кафка (Kafka Topic)||Kafka Topic]] = логический канал, в который [[Производитель Кафка (Kafka Producer)||производители (Producers)]] отправляют сообщения, а [[Потребитель Кафка (Kafka Consumer)||потребители (Consumers)]] читают их.
- Как работает [[Раздел Топика Кафка (Kafka Topic Partition)||партиционирование]] в Kafka? Почему это важно?
	- [[Раздел Топика Кафка (Kafka Topic Partition)||Kafka Topic Partition]] = подмножество [[Сообщение Кафка (Kafka Message)||сообщений]] внутри [[Топик Кафка (Kafka Topic)||топика]], которое позволяет обрабатывать данные параллельно.
	- Принцип работы – [[Сообщение Кафка (Kafka Message)||сообщения]] распределяются между [[Раздел Топика Кафка (Kafka Topic Partition)||партициями]] на основе ключа или случайным образом, а [[Потребитель Кафка (Kafka Consumer)||потребители]] читают их независимо.
	- Используется для масштабирования обработки данных, [[Балансировщик Нагрузки (Load Balancer)||балансировки нагрузки]] между [[Брокер Кафка (Kafka Broker)||брокерами]] и обеспечения порядка внутри [[Раздел Топика Кафка (Kafka Topic Partition)||партиции]].
- Что такое [[Смещение Кафка (Kafka Offset)||Kafka Offset]]? Как настроить его для [[Потребитель Кафка (Kafka Consumer)||потребителей]]?
	- [[Смещение Кафка (Kafka Offset)||Kafka Offset]] = уникальный идентификатор [[Сообщение Кафка (Kafka Message)||сообщения]] в [[Раздел Топика Кафка (Kafka Topic Partition)||партиции топика]], который позволяет [[Потребитель Кафка (Kafka Consumer)||потребителю]] отслеживать свою позицию при чтении [[Сообщение Кафка (Kafka Message)||сообщений]].
	- Настройка для [[Потребитель Кафка (Kafka Consumer)||потребителей]]:
		- **Автоматическое сохранение [[Смещение Кафка (Kafka Offset)||offset]]**: использование параметра `enable.auto.commit=true` для автоматического сохранения позиции после каждого [[Сообщение Кафка (Kafka Message)||сообщения]].
		- **Ручное сохранение offset**: отключение авто-коммита с помощью `enable.auto.commit=false` и явное сохранение [[Смещение Кафка (Kafka Offset)||offset]] с помощью метода `commitSync()` или `commitAsync()`.
		- **Режим чтения**: `auto.offset.reset` — настройка поведения [[Потребитель Кафка (Kafka Consumer)||потребителя]] при отсутствии сохранённого [[Смещение Кафка (Kafka Offset)||offset]]: `earliest` (с самого начала) или `latest` (с последнего).

##### Средне

- Как спроектировать систему с использованием [[Кафка (Apache Kafka)||Kafka]] так, чтобы обеспечить порядок сообщений между [[Раздел Топика Кафка (Kafka Topic Partition)||разделами]]?
	- Порядок [[Сообщение Кафка (Kafka Message)||сообщений]] сохраняется только внутри одной [[Раздел Топика Кафка (Kafka Topic Partition)||партиции]].
	- Используйте одну [[Раздел Топика Кафка (Kafka Topic Partition)||партицию]], если порядок критичен, но это ограничивает [[Масштабирование (Скейлинг, Scaling)||масштабируемость]].
	- Для нескольких [[Раздел Топика Кафка (Kafka Topic Partition)||партиций]] используйте [[Ключ Сообщения Кафка (Kafka Message Key)||ключи сообщений]] (например, идентификатор заказа), чтобы [[Сообщение Кафка (Kafka Message)||сообщения]] с одинаковым [[Ключ Сообщения Кафка (Kafka Message Key)||ключом]] попадали в одну [[Раздел Топика Кафка (Kafka Topic Partition)||партицию]] и сохраняли порядок.
	- [[Группа Потербителей Кафка (Kafka Consumer Group)||Consumer Groups]] могут распределять нагрузку, но порядок сохраняется только внутри [[Раздел Топика Кафка (Kafka Topic Partition)||партиции]].
	- Параллельная обработка сообщений из разных [[Раздел Топика Кафка (Kafka Topic Partition)||партиций]] нарушит порядок, если это важно.
- Как бы вы [[Сериализация (Serialization)||сериализовывали]] и десериализовывали [[Кафка (Apache Kafka)||сообщения Kafka]] с помощью [[{TODO} Java||Java]]? Сравните [[StringSerializer||StringSerializer]], [[JsonSerializer||JsonSerializer]] и [[Avro||Avro]]
	- [[StringSerializer||StringSerializer]] – простой и читаемый формат, но не поддерживает сложные [[Объект (Object)||объекты]] и не сохраняет структуру данных.
	- [[JsonSerializer||JsonSerializer]] – позволяет передавать сложные [[Объект (Object)||объекты]] в читаемом формате, но занимает больше места и не гарантирует совместимость схем.
	- [[Avro||Avro]] – бинарный формат с поддержкой схемы, обеспечивающий компактность и высокую производительность, но требует [[{TODO} Schema Registry||Schema Registry]].
- Что такое [[Группа Потербителей Кафка (Kafka Consumer Group)||группа потребителей (consumer group)]] в [[Кафка (Apache Kafka)||Kafka]]? Как она связана с параллельным потреблением (parallel consumption)?
	- [[Группа Потербителей Кафка (Kafka Consumer Group)||Consumer Group]] = это группа [[Потребитель Кафка (Kafka Consumer)||потребителей]], работающих вместе для чтения [[Сообщение Кафка (Kafka Message)||сообщений]] из одного или нескольких [[Топик Кафка (Kafka Topic)||топиков]] параллельно.
	- [[Группа Потербителей Кафка (Kafka Consumer Group)||Kafka Consumer Group]] позволяет параллельно читать [[Сообщение Кафка (Kafka Message)||сообщения]], распределяя [[Раздел Топика Кафка (Kafka Topic Partition)||партиции топика]] между потребителями так, что каждую [[Раздел Топика Кафка (Kafka Topic Partition)||партицию]] обрабатывает только один [[Потребитель Кафка (Kafka Consumer)||потребитель]] в [[Группа Потербителей Кафка (Kafka Consumer Group)||группе]].


##### Сложно

- Какие факторы влияют на [[Пропускная способность (Throughput)||пропускную способность (throughput)]] и [[Задержка (Latency)||задержки (latency)]] в [[Кафка (Apache Kafka)||Kafka]]? Как бы вы оптимизировали производительность [[Кафка (Apache Kafka)||Kafka]]?
	- **Факторы:**
		- **Размер [[Сообщение Кафка (Kafka Message)||сообщений]]**: Большие [[Сообщение Кафка (Kafka Message)||сообщения]] требуют больше времени на обработку и передачу, снижая [[Пропускная способность (Throughput)||пропускную способность]] и увеличивая [[Задержка (Latency)||задержку]].
		- **Число [[Раздел Топика Кафка (Kafka Topic Partition)||партиций]]**: Меньше [[Раздел Топика Кафка (Kafka Topic Partition)||партиций]] — ограничение на параллелизм, что может снизить [[Пропускная способность (Throughput)||пропускную способность]].
		- **Количество реплик**: [[Репликация (Replication)||Репликация]] данных увеличивает нагрузку на систему, повышая [[Задержка (Latency)||задержку]].
		- **Сетевые задержки**: Проблемы с сетью могут увеличить как [[Задержка (Latency)||задержку]], так и повлиять на [[Пропускная способность (Throughput)||пропускную способность]].
		- **Настройки [[Производитель Кафка (Kafka Producer)||Producer]] и [[Потребитель Кафка (Kafka Consumer)||Consumer]]**: Неверно настроенные параметры, такие как размер буфера, частота отправки и т. д., могут снижать производительность.
		- **Загрузка [[Брокер Кафка (Kafka Broker)||брокеров]]**: Когда [[Брокер Кафка (Kafka Broker)||брокеры]] перегружены, это может снизить [[Пропускная способность (Throughput)||скорость обработки данных]] и увеличить [[Задержка (Latency)||задержку]].
	- **Оптимизация производительности:**
		- **Увеличение числа [[Раздел Топика Кафка (Kafka Topic Partition)||партиций]]**: Это увеличивает параллелизм и улучшает [[Пропускная способность (Throughput)||пропускную способность]].
		- **Использование более компактных форматов данных** (например, [[Avro||Avro]] вместо [[{TODO} JSON||JSON]]).
		- **Настройка размера буферов**: Увеличение размера буферов для [[Производитель Кафка (Kafka Producer)||Producer]] и [[Потребитель Кафка (Kafka Consumer)||Consumer]] может уменьшить [[Задержка (Latency)||задержки]].
		- **Использование нескольких [[Брокер Кафка (Kafka Broker)||брокеров]]**: Распределение нагрузки между несколькими [[Брокер Кафка (Kafka Broker)||брокерами]] повышает общую [[Пропускная способность (Throughput)||пропускную способность]].
		- **[[Мониторинг (Monitoring)||Мониторинг]] и [[Масштабирование (Скейлинг, Scaling)||масштабирование]]**: Регулярно проверяйте нагрузку на систему и добавляйте [[Брокер Кафка (Kafka Broker)||брокеров]] или увеличивайте количество [[Раздел Топика Кафка (Kafka Topic Partition)||партиций]] при необходимости.
		- **Использование асинхронной записи**: Для [[Производитель Кафка (Kafka Producer)||Producer]] можно настроить асинхронную отправку [[Сообщение Кафка (Kafka Message)||сообщений]], чтобы улучшить [[Пропускная способность (Throughput)||throughput]].
- Что такое [[ISR (In-Sync Replicas)||ISR (In-Sync Replicas)]] в Kafka? Какую роль они играют в повышении надёжности?
	- [[ISR (In-Sync Replicas)||ISR]] = это список [[Реплика Раздела Кафка (Kafka Partition Replica)||реплик]], которые синхронизированы с лидером [[Раздел Топика Кафка (Kafka Topic Partition)||партиции]] и содержат актуальные данные.
	- Повышают надёжность, обеспечивая [[Отказоустойчивость (Fault Tolerance)||отказоустойчивость]], так как при сбое лидера [[Кафка (Apache Kafka)||Kafka]] выбирает новый лидер из [[ISR (In-Sync Replicas)||ISR]], минимизируя риск потери данных.
- Расскажите как [[Масштабирование (Скейлинг, Scaling)||масштабировать]] [[Производитель Кафка (Kafka Producer)||Kafka Producers]] и [[Потребитель Кафка (Kafka Consumer)||Consumers]] в приложении с высокой [[Пропускная способность (Throughput)||пропускной способностью]].
	- [[Масштабирование (Скейлинг, Scaling)||Масштабирование]] [[Производитель Кафка (Kafka Producer)||Производителей]]:
		- Увеличение количества [[Производитель Кафка (Kafka Producer)||продюсеров]] – Развертывание нескольких экземпляров [[Производитель Кафка (Kafka Producer)||продюсера]] для распределения нагрузки.
		- Настройка `acks`:
			- `acks=1` (быстрее, но возможна потеря [[Сообщение Кафка (Kafka Message)||сообщений]])
			- `acks=all` (надежнее, но медленнее)
		- Оптимизация `batch.size` и `linger.ms`:
			- Увеличение `batch.size` снижает нагрузку на сеть.
			- `linger.ms` позволяет накапливать данные перед отправкой.
		- Сжатие [[Сообщение Кафка (Kafka Message)||сообщений]] (`compression.type`) – Использование `snappy`, `lz4` или `zstd` для уменьшения нагрузки на сеть.
		- Настройка `buffer.memory` – Увеличение буфера [[Производитель Кафка (Kafka Producer)||продюсера]] для обработки пиковых нагрузок.
	- [[Масштабирование (Скейлинг, Scaling)||Масштабирование]] [[Потребитель Кафка (Kafka Consumer)||Потребителей]]:
		- [[Масштабирование (Скейлинг, Scaling)||Горизонтальное масштабирование]] – Увеличение количества экземпляров [[Потребитель Кафка (Kafka Consumer)||консьюмеров]] в пределах числа [[Раздел Топика Кафка (Kafka Topic Partition)||партиций]].
		- Оптимальный `max.poll.records` и `fetch.min.bytes` – Баланс между [[Пропускная способность (Throughput)||пропускной способностью]] и [[Задержка (Latency)||задержкой обработки]].
		- Автоматический контроль смещения (`enable.auto.commit=false`) – Гибкость в обработке и надежность при отказах.
		- Разделение логики обработки и чтения – Использование [[Очередь Сообщений (Message Queue)||очередей]] (например, [[{TODO} Redis||Redis]], [[{TODO} RabbitMQ||RabbitMQ]]) между [[Потребитель Кафка (Kafka Consumer)||консьюмерами]] и обработчиками.
		- Тюнинг `session.timeout.ms` и `heartbeat.interval.ms` – Для корректного управления групповым [[Балансировщик Нагрузки (Load Balancer)||балансировщиком]].
	- Дополнительно:
		- Настроить [[Брокер Кафка (Kafka Broker)||Kafka Broker’ы]] (увеличение [[Раздел Топика Кафка (Kafka Topic Partition)||партиций]], `replication.factor`, `num.network.threads`).
		- Использовать [[Стрим Кафка (Kafka Stream)||Kafka Streams]] или [[Apache Flink||Flink]] для потоковой обработки с автоматическим [[Масштабирование (Скейлинг, Scaling)||масштабированием]].
		- [[Мониторинг (Monitoring)||Мониторинг]] через Prometheus + Grafana для отслеживания задержек и загрузки.
- Что такое [[Kafka Connect||Kafka Connect]]? Какую роль он играет в интеграции [[Кафка (Apache Kafka)||Kafka]] с другими системами?
	- **Kafka Connect** = фреймворк для интеграции [[Кафка (Apache Kafka)||Kafka]] с внешними системами, позволяющий легко загружать и выгружать данные без написания сложного кода.
	- Управляет потоками данных через коннекторы, обеспечивая [[Масштабирование (Скейлинг, Scaling)||масштабируемость]], [[Отказоустойчивость (Fault Tolerance)||отказоустойчивость]] и упрощённую конфигурацию.


##### Очень сложно

- Для чего делать [[Реплика Раздела Кафка (Kafka Partition Replica)||репликации в Kafka]]? Как они обеспечивают [[Отказоустойчивость (Fault Tolerance)||отказоустойчивость (fault tolerance)]]?
	- [[Реплика Раздела Кафка (Kafka Partition Replica)||Репликация разделов в Kafka]] обеспечивает сохранность данных и [[Отказоустойчивость (Fault Tolerance)||отказоустойчивость]], дублируя [[Сообщение Кафка (Kafka Message)||сообщения]] на несколько [[Брокер Кафка (Kafka Broker)||брокеров]]. 
	- Если ведущий [[Брокер Кафка (Kafka Broker)||брокер]] выходит из строя, один из [[Реплика Раздела Кафка (Kafka Partition Replica)||реплик]] становится новым лидером, позволяя системе продолжать работу без потери данных.
- Чем [[Кафка (Apache Kafka)||Kafka]] отличается от традиционных [[Очередь Сообщений (Message Queue)||Очередей Сообщений]], таких как [[{TODO} RabbitMQ||RabbitMQ]] или [[{TODO} ActiveMQ||ActiveMQ]]?
	- **Модель потребления** — [[Кафка (Apache Kafka)||Kafka]] использует pull-модель ([[Потребитель Кафка (Kafka Consumer)||читатели]] управляют [[Смещение Кафка (Kafka Offset)||смещением]]), а [[Очередь Сообщений (Message Queue)||очереди]] — push-модель ([[Сообщение Кафка (Kafka Message)||сообщения]] доставляются автоматически).
	- **Хранение сообщений** — [[Кафка (Apache Kafka)||Kafka]] хранит данные в логах заданное время, а [[Очередь Сообщений (Message Queue)||очереди]] удаляют их после обработки.
	- **Производительность** — [[Кафка (Apache Kafka)||Kafka]] оптимизирована для высокой [[Пропускная способность (Throughput)||пропускной способности]] и [[Масштабирование (Скейлинг, Scaling)||горизонтального масштабирования]].
	- **[[Масштабирование (Скейлинг, Scaling)||Масштабируемость]]** — [[Кафка (Apache Kafka)||Kafka]] поддерживает [[Реплика Раздела Кафка (Kafka Partition Replica)||партиционирование]] и распределённые кластеры, а [[Очередь Сообщений (Message Queue)||очереди]] сложнее [[Масштабирование (Скейлинг, Scaling)||масштабировать]].
	- **[[Типы доставки в Кафка (Kafka Delivery Types)||Гарантии доставки]]** — [[Кафка (Apache Kafka)||Kafka]] поддерживает `at-least-once` и `exactly-once` (с доп. настройками), в то время как [[Очередь Сообщений (Message Queue)||очереди]] обычно используют `at-most-once` или `at-least-once`.
	- **Обработка сообщений** — В [[Кафка (Apache Kafka)||Kafka]] один [[Топик Кафка (Kafka Topic)||топик]] может [[Потребитель Кафка (Kafka Consumer)||потребляться]] разными группами независимо, а в [[Очередь Сообщений (Message Queue)||очередях]] сообщение обычно доставляется только одному потребителю.
	- **[[Отказоустойчивость (Fault Tolerance)||Отказоустойчивость]]** — [[Кафка (Apache Kafka)||Kafka]] реплицирует данные на несколько [[Брокер Кафка (Kafka Broker)||брокеров]], в [[Очередь Сообщений (Message Queue)||традиционных очередях]] репликация менее развита.
	- **Сценарии использования** — [[Кафка (Apache Kafka)||Kafka]] лучше подходит для потоковой обработки данных и [[Логирование (Logging)||логирования]], а [[Очередь Сообщений (Message Queue)||очереди]] — для традиционного [[Брокер Сообщений (Message Broker)||брокеринга сообщений]] и RPC.
- В чём заключается задача [[Производитель Кафка (Kafka Producer)||Producer'а]] в [[Кафка (Apache Kafka)||Kafka]]? Как он обеспечивает надёжную доставку [[Сообщение Кафка (Kafka Message)||сообщений]]?
	- Задача [[Производитель Кафка (Kafka Producer)||Producer’а]] = отправлять [[Сообщение Кафка (Kafka Message)||сообщения]] в [[Топик Кафка (Kafka Topic)||топики]], распределяя их по разделам ([[Раздел Топика Кафка (Kafka Topic Partition)||partitions]]).
	- Как обеспечивается надёжная доставка:
		- **Подтверждения (acks)** — [[Производитель Кафка (Kafka Producer)||Producer]] ждёт подтверждение от [[Брокер Кафка (Kafka Broker)||брокеров]] (`acks=1` или `acks=all` для гарантированной доставки).
		- **[[Идемпотентность (Idempotency)||Idempotent]] [[Производитель Кафка (Kafka Producer)||Producer]]** — предотвращает дубликаты при повторных отправках.
		- **Ретрансмиссия (Retries)** — повторяет отправку [[Сообщение Кафка (Kafka Message)||сообщений]] при временных сбоях.
		- **Распределение по разделам** — ключи сообщений ([[Ключ Сообщения Кафка (Kafka Message Key)||key]]) помогают направлять данные в нужный раздел для упорядоченности.
- Каковы основные конфигурации [[Производитель Кафка (Kafka Producer)||Kafka Producer'а]] в [[{TODO} Java||Java]]?
	- Настройки доставки [[Сообщение Кафка (Kafka Message)||сообщений]]:
		- `acks=0/1/all` — уровень подтверждений (`0` — не ждать, `1` — от лидера, `all` — от всех [[ISR (In-Sync Replicas)||реплик]]).
		- `retries` — количество попыток повторной отправки при сбоях.
		- `linger.ms` — задержка перед отправкой (для объединения [[Сообщение Кафка (Kafka Message)||сообщений]] в батчи).
		- `batch.size` — размер батча [[Сообщение Кафка (Kafka Message)||сообщений]].
	- Надёжность и порядок:
		- `enable.idempotence=true` — предотвращение дубликатов ([[Типы доставки в Кафка (Kafka Delivery Types)||exactly-once]]).
		- `max.in.flight.requests.per.connection` — ограничение параллельных отправок (ставим `1` для строгого порядка).
	- Производительность:
		- `compression.type=none/gzip/snappy/lz4/zstd` — сжатие [[Сообщение Кафка (Kafka Message)||сообщений]].
		- `buffer.memory` — размер буфера [[Сообщение Кафка (Kafka Message)||сообщений]] в [[Производитель Кафка (Kafka Producer)||продюсере]].
	- Распределение [[Сообщение Кафка (Kafka Message)||сообщений]]:
		- `key.serializer / value.serializer` — [[Сериализация (Serialization)||сериализаторы]] для [[Ключ Сообщения Кафка (Kafka Message Key)||ключей]] и значений [[Сообщение Кафка (Kafka Message)||сообщений]].
		- `partitioner.class` — кастомная логика распределения по [[Раздел Топика Кафка (Kafka Topic Partition)||разделам]].
- Как [[Потребитель Кафка (Kafka Consumer)||Kafka Consumer]] справляется с управлением [[Смещение Кафка (Kafka Offset)||offset]]? В чём разница между авто-коммитом и ручным управлением [[Смещение Кафка (Kafka Offset)||offset]]?
	- Управление [[Смещение Кафка (Kafka Offset)||offset]]:
		- [[Кафка (Apache Kafka)||Kafka]] отслеживает [[Смещение Кафка (Kafka Offset)||offset]] (позицию в [[Топик Кафка (Kafka Topic)||топике]]) для каждого [[Потребитель Кафка (Kafka Consumer)||потребителя]].
		- [[Смещение Кафка (Kafka Offset)||Offset]] может автоматически или вручную фиксироваться (`commit`), чтобы избежать потери или дублирования [[Сообщение Кафка (Kafka Message)||сообщений]].
	- Разница между авто-коммитом и ручным управлением [[Смещение Кафка (Kafka Offset)||offset]]:
		- Авто-коммит (`enable.auto.commit=true`)
			- Kafka автоматически сохраняет [[Смещение Кафка (Kafka Offset)||offset]] через заданный интервал (`auto.commit.interval.ms`).
			- Просто в использовании, но возможны потери или дублирование [[Сообщение Кафка (Kafka Message)||сообщений]] при сбоях.
		- Ручное управление (`enable.auto.commit=false`)
			- [[Потребитель Кафка (Kafka Consumer)||Потребитель]] сам подтверждает обработку через `commitSync()` (синхронно) или `commitAsync()` (асинхронно).
			- Даёт больше контроля, снижает риск потерь, но требует внимательной обработки ошибок.
		- Лучший вариант — ручное управление с `commitSync()` или `commitAsync()` для контроля над обработкой [[Сообщение Кафка (Kafka Message)||сообщений]].
- В чём задача [[Стрим Кафка (Kafka Stream)||Kafka Streams]] и чем они отличаются от стандартных [[Потребитель Кафка (Kafka Consumer)||Kafka Consumers]]?
	- [[Стрим Кафка (Kafka Stream)||Kafka Stream]] = Обрабатывает данные в реальном времени, позволяя применять трансформации, агрегировать и соединять потоки [[Сообщение Кафка (Kafka Message)||сообщений]].
	- [[Потребитель Кафка (Kafka Consumer)||Kafka Consumer]] = Просто читает [[Сообщение Кафка (Kafka Message)||сообщения]] из [[Топик Кафка (Kafka Topic)||топика]] без встроенной логики обработки и трансформаций.
- Объясните в чём разница между «at-least-once», «at-most-once» и «exactly-once» [[Типы доставки в Кафка (Kafka Delivery Types)||типами доставки в Kafka]].
	- **all-at-once** = гарантия, что [[Сообщение Кафка (Kafka Message)||сообщение]] будет доставлено хотя бы один раз, но возможны дубликаты.
	- **at-most-once** = [[Сообщение Кафка (Kafka Message)||сообщение]] доставляется не более одного раза, но может потеряться в случае сбоя.
	- **exactly-once** = [[Сообщение Кафка (Kafka Message)||сообщение]] обрабатывается строго один раз, без потерь и дублирования, но требует дополнительной настройки.
---
## Design questions

- Let’s assume we have a task to call some external API, for example to perform identity verification of a client. We need to build an integration with 3rd party from scratch. Each API call costs us money. What are the most important things you would do to make sure it works correctly? What should be considered first?
- How would you design the account deposit/withdrawal feature high level in micreservice architecture where you have payment and core service running independently with their own databases. What locking mechanisms to use and how to coordinate interservice communication?
- Предположим, у нас есть задача вызвать некий внешний API, например, для проверки личности клиента. Нам нужно построить интеграцию со сторонними организациями с нуля. Каждый вызов API стоит нам денег. Какие самые важные вещи вы бы сделали, чтобы убедиться, что все работает правильно? Что следует рассмотреть в первую очередь?
- Как бы вы спроектировали функцию депозита/снятия средств на счете высокого уровня в архитектуре микросервиса, где у вас есть платежная и основная службы, работающие независимо друг от друга с собственными базами данных. Какие механизмы блокировки использовать и как координировать межсервисную связь?

---
## Memory Management

- What is Java Memory Model? Describe purpose and basic ideas.
- What «Stop-The-World» means?
- When does an object become eligible for garbage collection? Describe how the GC collects an eligible object
- What is stored in heap and stack memories?
- What spacial guerentees Does the JMM hold for final fiels of a class?

---
## Cultural Fit

- How would you give feedback to a teammate who made a mistake which caused you to work extra hours?
- Describe when you faced a technical problem you couldn’t solve immediateley. What steps did you take to find a solution?
- How wave you handled a situation where you were under a lot of pressure to solve a technical problem?
- Can you share an instance where your team faced a significant technical problem? How did you contribute to the solution?
- Describe a time when you had to collaborate with a colleague who had a different approach to problem-solving. How did you handle it?
- Can you share an example of a technical project where you had to make a critical decision? How did you evaluate your options?
- Can you share a time when a project did not go as planned and you had to change your approach midway?
- How do you keep yourself updated with the latest advancements in your field?
- How have you adapted to a significant change at work, such as new software or change in team structure?
- Describe a time when you had to jiggle multiple tasks at once. How did you ensure everything got done?
- Can you tell me about a time when a project’s deadline changed suddenly? How did you adjust your plans?
- Describe a time when a tech project didn’t go as planned. How did you managed your stress?
- Tell me about the time when you had to work under a lot of pressure. What was going on and how did you handle it?

---

## Coding Tasks

library

  

Sufficient level:

6. TDD

7. thread safe code

8. corner cases

9. would be nice to add new books to library

Advanced level:

10. fair queue

11. improve concurrency

a. maybe cas

12. concurrency scope

a. book level

i. if we have a lot of books - too many locks

b. other criteria for lock

i. buckets, hash, genre

  

2 ?

  

Sufficient level:

13. logging should not block our app

14. log delivery

a. all should be persisted

b. can we skip something

15. should not produce a lot of garbage

a. avoid OOk

16. s o u r c e c o d e

a. base classes like here

17. separate thread for persist to file. Working thread safe code.

Advanced level:

We have a lot of logs and we want to process them more quickly.

18. thread safe size bounded queue

a. overflow queue - block or discard

19. batch persist with configs batch.size and timeout

20. ring buffer instead of queue

  

elevator

  

Sufficient level:

21. TDD

22. implementation of 2 user actions

a . r e q u e s t E l e v a t o r

b . s e n d E l e v a t o r

23. thread safe implementation

a. synchronized or lock

24. corner case handling

Advanced level:

25. fair request queue

26. we want to have possibility not to block on class level

a. more concurrent approaches

b. lock by elevator ?? TODO

---

  






  

**Screenshot 17, 18, 19, 20 (Interview test)**

Databases:

- group by, having
- explain
- indexes
- index exist but not used
- transactions
- isolation level
- optimistic lock
- pessimistic lock
- replication
- how to do partitioning
- how to do sharding

ORM:

- N + 1
- cache levels

Data Structures:

- tree - search - complexity
- balanced tree
- hashtable - O(1) and details
- collision resolution
- recursion
- tail recursion
- lock free approach
- bloom filter

Concurrency:

- rest execution concurrency
- servlet container

```
I++ task:

private int i;

  

@PostMapping(value = "test")

void m(){

    i++;

}
```

- not thread safe
- atomic
- sync + volatile
- the same order for sync, fair locks
- util.locks
- happens before
- thread pools, fork join feature

Garbage Collection:

- ZGC, Shenandoah
- G1GC
- latency and STW
- how to see it
- stack vs heap
- escape analysis

Profiling:

- jprofiler
- visualvm
- async profiler
- JFR
- heap dump
- thread dump example
- safepoint bias code example
- sampling vs instrumenting

Spring:

- AOP 
- AOP proxy self execution

Containers:

- docker
- dockerfile
- docker vs virtual machine vs bare metal
- k8s
- kubectl

- deploy update
- go into containre
- port forward

- ci/cd

Kafka:

- topic, partition, broker
- ordering
- parallelism
- delivery semantics

- exactly once is possible?
- at least one

- Producer semantics

- acks
- batches

Security:

- how to store password
- secure api (https)
- encryption vs hashing
- symmetric encryption
- asymmetric encryption
- how https works
- certificates, authority
- keystore, truststore
- how to sign request

Newtworks:

- tcp udp
- websockets
- dns
- protobuf
- grpc
- http 1.1(rest) vs 2(2 way) vs 3(quick)

Design patterns:

- saga
- cqrs
- event sourcing
- transactional outbox
- circuit breaker
- GOF
- SOLID
- GRASP

Algorythms:

- what sorting is used in Java?
- quick sort, merge sort

- complexity
- best case
- worst case
- adwantages

- LSM why rocks, tarantool so fast

Tasks:

- Let’s assume we have a task to call some external API, for example to perform identity verification of a client. We need to build an integration with 3rd party from scratch. Each API call costs us money. What are the most important things you would do to make sure it works correctly? What should be considered first?

  

**Screenshot 21, 22**

  

Theory part = 45-60 min

Coding part = 45 - 60 min

  

Theory:

To start a conversation, it's always interesting to learn what the person has been doing over the past year or two. This is the most relevant experience worth di

Once the person shares their story, review our list of topics and questions, select the ones that align with their described experience, and try to assess how di

understand the subject and how well they are understand it. Do not turn the interview into a question-and-answer session; give the person an opportunity to t

what they have done.

During the theoretical discussion, you should preliminary assess the person's level of knowledge. If you believe their knowledge level is insufficient, there is n

conducting a coding interview, and the interview can be stopped.

  

Coding:

How to start coding interview

› How to start coding interview details

Requirements:

27. Minimum; the first and minimal requirement is that the person must write a fully functional solution along with tests for it. It should run, execute, and g

Even if it operates in single-threaded mode or is not optimized, it must have a clear interface and work correctly.

28. Middle: the person must understand where multi threading issues can arise and should be able to pinpoint the exact lines of their code that need to t

They should write thread-safe code, regardless of how it is achieved - whether by using a single synchronized keyword or concurrent collections. If

thread-safe, the task is considered complete.

29. High: the solution must be optimized for maximum performance, minimizing or completely eliminating locks to ensure the highest possible throughp

approaches the person can propose to achieve this, the better.

After the interview push code to dev/name_surname branch (for history and analysis)

  
  

